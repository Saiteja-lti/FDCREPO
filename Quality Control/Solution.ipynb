{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b302df2b-661e-4dcd-9b55-6060a7affb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/9d/d332ec76e2cc442fce98bc43a44e69d3c281e6b4ede6b6db2616dc6fbec6/scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4MB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f5/d0ad1a96f80962ba65e2ce1de6a1e59edecd1f0a7b55990ed208848012e0/scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6MB)\n",
      "\u001b[K     |████████████████████████████████| 38.6MB 110.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl\n",
      "Collecting joblib>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 80.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Installing collected packages: scipy, threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.13.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0234f4-aa2b-4d44-aaf2-f005aeabfecc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fosforml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_manager\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowflakesession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_session\n\u001b[1;32m      2\u001b[0m my_session \u001b[38;5;241m=\u001b[39m get_session()\n\u001b[1;32m      4\u001b[0m table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSOLUTION_TABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fosforml'"
     ]
    }
   ],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"SOLUTION_TABLE\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "data = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74621208-5ea6-4984-9a4a-0b51e0e14987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fosforml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/2e/3613fd0ccdbf3709dec86f87fe7624737a6f08bd1a813c88e65e7352dfde/fosforml-1.1.8-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting scikit-learn==1.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/89/dce01a35d354159dcc901e3c7e7eb3fe98de5cb3639c6cd39518d8830caa/scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9MB 10.7MB/s eta 0:00:01MB 10.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-ml-python==1.5.0; python_version <= \"3.9\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/c0fa5a9bc811a59a5a1c7113ff89676ed1629d7d6463db8c1a8c97a8b5f6/snowflake_ml_python-1.5.0-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 110.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==2.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.26.4)\n",
      "Collecting s3fs<2024,>=2022.11\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/d6/b8a748b7d3fc7b0fd2ede1cf26a80281d65cc24d5d56b66c3a4c87e256e2/s3fs-2023.12.2-py3-none-any.whl\n",
      "Collecting pyarrow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/19/1e47418efd3fadf343cc3c01703aba76e327e4f2224a1d137b7e2e5647ec/pyarrow-18.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.1MB)\n",
      "\u001b[K     |████████████████████████        | 30.0MB 79.6MB/s eta 0:00:01\u001b[?25hCollecting catboost<1.3,>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/4a/8ada4fb635601943805cbeeb288f70982fefe48a7cef63352e318435aa98/catboost-1.2.7-cp39-cp39-manylinux2014_x86_64.whl (98.7MB)\n",
      "\u001b[K     |████████████████████████████████| 98.7MB 341kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-connector-python[pandas]<4,>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/83/f8b30648768b33fa28786932164db320d9fce662dfe1cbd4c6031736b9b2/snowflake_connector_python-3.12.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 109.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<6,>=3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (4.12.2)\n",
      "Collecting snowflake-snowpark-python!=1.12.0,<2,>=1.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/55/3cbf9670a6cc14690aa9c3cc279a5e6d8dc74ef2deb8ce6f8fb7d8268a35/snowflake_snowpark_python-1.25.0-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 106.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]<2024,>=2022.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/25/fab23259a52ece5670dcb8452e1af34b89e6135ecc17cd4b54b4b479eac6/fsspec-2023.12.2-py3-none-any.whl (168kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 91.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying<2,>=1.3.3\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/04/9e36f28be4c0532c0e9207ff9dc01fb13a2b0eb036476a213b0000837d0e/retrying-1.3.4-py3-none-any.whl\n",
      "Collecting absl-py<2,>=0.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/87/de5c32fa1b1c6c3305d576e299801d8655c175ca9557019906247b994331/absl_py-1.4.0-py3-none-any.whl (126kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 96.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources<7,>=6.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl\n",
      "Requirement already satisfied: pandas<3,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.2.0)\n",
      "Collecting xgboost<2,>=1.7.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/3a/c9c5d4d5c49b132ef15ac7b5ccf56ef1c82efe36cd19414771762e97c00e/xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3MB)\n",
      "\u001b[K     |████████████████████████████████| 200.3MB 128kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting aiobotocore<3.0.0,>=2.5.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/57/6402242dde160d9ef9903487b4277443dc3da04615f6c4d3b48564a8ab57/aiobotocore-2.15.2-py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 31.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/48/51d3af146bb35988072d0456faadec603ac40e1d4974de07d1bf11065f2b/aiohttp-3.11.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 94.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from catboost<1.3,>=1.2.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.16.0)\n",
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/20/f56d5b88450593ccde3f283e338f3f976b2e479bddd9a147f14f66ee1ca7/matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3MB)\n",
      "\u001b[K     |████████████████████████████████| 8.3MB 63.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting graphviz\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/be/d59db2d1d52697c6adc9eacaf50e8965b6345cc143f671e1ed068818d5cf/graphviz-0.20.3-py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 21.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/ae/580600f441f6fc05218bd6c9d5794f4aef072a7d9093b291f1c50a9db8bc/plotly-5.24.1-py3-none-any.whl (19.1MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1MB 100.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tomlkit\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl\n",
      "Collecting filelock<4,>=3.5\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/f8/feced7779d755758a52d1f6635d990b8d98dc0a29fa568bbe0625f18fdf3/filelock-3.16.1-py3-none-any.whl\n",
      "Requirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (42.0.5)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.3.2)\n",
      "Collecting sortedcontainers>=2.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.16.0)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/7f/09065fd9e27da0eda08b4d6897f1c13535066174cc023af248fc2a8d5e5a/asn1crypto-1.5.1-py2.py3-none-any.whl (105kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 117.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.1)\n",
      "Collecting urllib3<2.0.0,>=1.21.1; python_version < \"3.10\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/cf/8435d5a7159e2a9c83a95896ed596f68cf798005fe107cc655b5c5c14704/urllib3-1.26.20-py2.py3-none-any.whl (144kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 110.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyjwt<3.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/1d/ef9b066e7ef60494c94173dc9f0b9adf5d9ec5f888109f5c669f53d4144b/PyJWT-2.10.0-py3-none-any.whl\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (24.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.7.4)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (4.2.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python!=1.12.0,<2,>=1.11.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python!=1.12.0,<2,>=1.11.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (65.6.3)\n",
      "Collecting tzlocal\n",
      "  Downloading https://files.pythonhosted.org/packages/97/3f/c4c51c55ff8487f2e6d0e618dba917e3c3ee2caae6cf0fbb59c9b1876f2e/tzlocal-5.2-py3-none-any.whl\n",
      "Collecting protobuf<6,>=3.20\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/ae/3257b09328c0b4e59535e497b0c7537d4954038bdd53a2f0d2f49d15a7c4/protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 90.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from importlib-resources<7,>=6.1.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas<3,>=1.0.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas<3,>=1.0.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.1)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/85/13/58b70a580de00893223d61de8fea167877a3aed97d4a5e1405c9159ef925/aioitertools-0.12.0-py3-none-any.whl\n",
      "Collecting botocore<1.35.37,>=1.35.16\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/60/056d58b606731f94fe395266c604ea9efcecc10e6857ceb9b10e6831d746/botocore-1.35.36-py3-none-any.whl (12.6MB)\n",
      "\u001b[K     |████████████████████████████████| 12.6MB 110.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt<2.0.0,>=1.10.10\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/5c/03c911442b01b50e364572581430e12f82c3f5ea74d302907c1449d7ba36/wrapt-1.17.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 34.5MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/8b/a9f89dbb9322a5c7be24bc11b06dab031932808b69f8be65f0ab149b7a59/yarl-1.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 101.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d8/120cd0fe3e8530df0539e71ba9683eade12cae103dd7543e50d15f737917/aiohappyeyeballs-2.4.3-py3-none-any.whl\n",
      "Collecting multidict<7.0,>=4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/41/0d0fb18c1ad574f807196f5f3d99164edf9de3e169a58c6dc2d6ed5742b9/multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 88.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/33/9f152105227630246135188901373c4f322cc026565ca6215b063f4c82f4/frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 98.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting propcache>=0.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4e/97059dd24494d1c93d1efb98bb24825e1930265b41858dd59c15cb37a975/propcache-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 100.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/b1/c8f428bae932a27ce9c87e7b21aba8ea3e820aa11413c5a795868c37e039/pillow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3MB 106.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl\n",
      "Collecting contourpy>=1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/11/57335544a3027e9b96a05948c32e566328e3a2f84b7b99a325b7a06d2b06/contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 104.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/3e/0841e7bf38ad317c960992dd03bac041899a1c21396013e6ddcfd2bc48c5/fonttools-4.55.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6MB 62.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/ec/2eb3cd785efd67806c46c13a17339708ddc346cbb684eade7a6e6f79536a/pyparsing-3.2.0-py3-none-any.whl (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 104.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/b1/40655f6c3fa11ce740e8a964fa8e4c0479c87d6a7944b95af799c7a55dfe/kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 99.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.21)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/31/b4/b9b800c45527aadd64d5b442f9b932b00648617eb5d63d2c7a6587b7cafc/jmespath-1.0.1-py3-none-any.whl\n",
      "Installing collected packages: scikit-learn, async-timeout, frozenlist, aiosignal, propcache, multidict, yarl, aiohappyeyeballs, aiohttp, aioitertools, urllib3, jmespath, botocore, wrapt, aiobotocore, fsspec, s3fs, pyarrow, sqlparse, packaging, pytimeparse, anyio, cloudpickle, pillow, importlib-resources, cycler, contourpy, fonttools, pyparsing, kiwisolver, matplotlib, graphviz, tenacity, plotly, catboost, tomlkit, filelock, sortedcontainers, asn1crypto, pyjwt, snowflake-connector-python, cachetools, tzlocal, protobuf, snowflake-snowpark-python, retrying, absl-py, xgboost, snowflake-ml-python, fosforml\n",
      "  Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "  Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Found existing installation: anyio 4.4.0\n",
      "    Uninstalling anyio-4.4.0:\n",
      "      Successfully uninstalled anyio-4.4.0\n",
      "Successfully installed absl-py-1.4.0 aiobotocore-2.15.2 aiohappyeyeballs-2.4.3 aiohttp-3.11.7 aioitertools-0.12.0 aiosignal-1.3.1 anyio-3.7.1 asn1crypto-1.5.1 async-timeout-5.0.1 botocore-1.35.36 cachetools-5.5.0 catboost-1.2.7 cloudpickle-2.2.1 contourpy-1.3.0 cycler-0.12.1 filelock-3.16.1 fonttools-4.55.0 fosforml-1.1.8 frozenlist-1.5.0 fsspec-2023.12.2 graphviz-0.20.3 importlib-resources-6.4.5 jmespath-1.0.1 kiwisolver-1.4.7 matplotlib-3.9.2 multidict-6.1.0 packaging-23.2 pillow-11.0.0 plotly-5.24.1 propcache-0.2.0 protobuf-5.28.3 pyarrow-18.0.0 pyjwt-2.10.0 pyparsing-3.2.0 pytimeparse-1.1.8 retrying-1.3.4 s3fs-2023.12.2 scikit-learn-1.3.2 snowflake-connector-python-3.12.3 snowflake-ml-python-1.5.0 snowflake-snowpark-python-1.25.0 sortedcontainers-2.4.0 sqlparse-0.5.2 tenacity-9.0.0 tomlkit-0.13.2 tzlocal-5.2 urllib3-1.26.20 wrapt-1.17.0 xgboost-1.7.6 yarl-1.18.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fosforml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26336f7-e9c5-4edf-96e3-dde207c48c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"SOLUTION_TABLE\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "data = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a01f333-afac-4e76-8334-24e12f9d2406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRODUCT_ID', 'Car_Company', 'YIELD_RATE', 'SHIFT', 'MACHINE_ID',\n",
       "       'OPERATOR_ID', 'MATERIAL_BATCH', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME',\n",
       "       'DEFECT_COUNT', 'MAINTENANCE_SCHEDULE', 'TRACK_OUT_DATE',\n",
       "       'MANUFACTURE_DATE', 'MODEL_NAME', 'YEAR_OF_MANUFACTURE', 'ENGINE_TYPE',\n",
       "       'FUEL_TYPE', 'TRANSMISSION_TYPE', 'BODY_STYLE', 'Price', 'Mileage',\n",
       "       'SEATING_CAPACITY', 'COLOR_OPTIONS', 'SAFETY_FEATURES',\n",
       "       'Warranty_Period', 'Horsepower', 'Torque', 'Top_Speed', 'Acceleration',\n",
       "       'Dimensions', 'Weight', 'Fuel_Tank_Capacity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa68ebf-3888-4c9d-aa77-0673bdea5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "129e23d2-dc76-47ee-9cf2-866506f67b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a514aa4c-df29-44ae-a9a3-bdab43b3f4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.7209152e+18 1.7165952e+18 1.7146944e+18 1.7174592e+18 1.7108927e+18\n 1.7260128e+18 1.7116704e+18 1.7025984e+18 1.7217791e+18 1.7098560e+18\n 1.7147807e+18 1.7202240e+18 1.7216928e+18 1.7203105e+18 1.7086464e+18\n 1.7248032e+18 1.7254944e+18 1.7007840e+18 1.7010432e+18 1.7074368e+18\n 1.7152992e+18 1.7113248e+18 1.7308512e+18 1.7283456e+18 1.7258400e+18\n 1.7236801e+18 1.7189280e+18 1.7300736e+18 1.7164225e+18 1.7121888e+18\n 1.7127072e+18 1.7305920e+18 1.7118433e+18 1.7104608e+18 1.7006112e+18\n 1.7053632e+18 1.7274816e+18 1.7196191e+18 1.7267040e+18 1.7082145e+18\n 1.7214336e+18 1.7233344e+18 1.7184960e+18 1.7161632e+18 1.7187552e+18\n 1.7231616e+18 1.7140033e+18 1.7159903e+18 1.7123615e+18 1.7229024e+18\n 1.7234208e+18 1.7122752e+18 1.7149536e+18 1.7083008e+18 1.7191009e+18\n 1.7119296e+18 1.7093376e+18 1.7057953e+18 1.7247168e+18 1.7299008e+18\n 1.7301600e+18 1.7309377e+18 1.7059680e+18 1.7089056e+18 1.7028576e+18\n 1.7186688e+18 1.7318880e+18 1.7256671e+18 1.7035488e+18 1.7078688e+18\n 1.7121023e+18 1.7134848e+18 1.7277408e+18 1.7045857e+18 1.7253216e+18\n 1.7200513e+18 1.7142625e+18 1.7112384e+18 1.7016480e+18 1.7145215e+18\n 1.7088192e+18 1.7251489e+18 1.7017343e+18 1.7013888e+18 1.7197056e+18\n 1.7107200e+18 1.7177184e+18 1.7126208e+18 1.7218656e+18 1.7092512e+18\n 1.7073504e+18 1.7291232e+18 1.7232479e+18 1.7269632e+18 1.7159040e+18\n 1.7057088e+18 1.7155584e+18 1.7310240e+18 1.7204832e+18 1.7279136e+18\n 1.7215201e+18 1.7055360e+18 1.7180640e+18 1.7199648e+18 1.7166817e+18\n 1.7051904e+18 1.7223840e+18 1.7004384e+18 1.7170272e+18 1.7267904e+18\n 1.7169407e+18 1.7171999e+18 1.7022528e+18 1.7111519e+18 1.7270496e+18\n 1.7311969e+18 1.7032032e+18 1.7302463e+18 1.7101152e+18 1.7100288e+18\n 1.7080416e+18 1.7201376e+18 1.7019936e+18 1.7011296e+18 1.7293824e+18\n 1.7172864e+18 1.7003520e+18 1.7288640e+18 1.7235072e+18 1.7205695e+18\n 1.7268767e+18 1.7282592e+18 1.7109792e+18 1.7050176e+18 1.7281728e+18\n 1.7252352e+18 1.7065728e+18 1.7207424e+18 1.7278271e+18 1.7284320e+18\n 1.7025120e+18 1.7063135e+18 1.7314559e+18 1.7152129e+18 1.7190144e+18\n 1.7241983e+18 1.7216064e+18 1.7292959e+18 1.7188417e+18 1.7296416e+18\n 1.7230752e+18 1.7299873e+18 1.7289504e+18 1.7031168e+18 1.7085600e+18\n 1.7129664e+18 1.7087327e+18 1.7171136e+18 1.7018208e+18 1.7162496e+18\n 1.7157311e+18 1.7156448e+18 1.7295552e+18 1.7090784e+18 1.7056224e+18\n 1.7102016e+18 1.7038943e+18 1.7114976e+18 1.7273089e+18 1.7066592e+18\n 1.7060545e+18 1.7024257e+18 1.7154721e+18 1.7075231e+18 1.7099423e+18\n 1.7211744e+18 1.7114112e+18 1.7070049e+18 1.7246304e+18 1.7077824e+18\n 1.7131392e+18 1.7194464e+18 1.7167680e+18 1.7076960e+18 1.7249760e+18\n 1.7127937e+18 1.7105472e+18 1.7083872e+18 1.7097696e+18 1.7318016e+18\n 1.7049312e+18 1.7179776e+18 1.7046720e+18 1.7081280e+18 1.7212609e+18\n 1.7173728e+18 1.7163360e+18 1.7084735e+18 1.7272224e+18 1.7014751e+18\n 1.7008704e+18 1.7276544e+18 1.7265312e+18 1.7243712e+18 1.7136576e+18\n 1.7042400e+18 1.7120160e+18 1.7160768e+18 1.7039808e+18 1.7192736e+18\n 1.7224705e+18 1.7158176e+18 1.7316288e+18 1.7168544e+18 1.7198784e+18\n 1.7238528e+18 1.7032896e+18 1.7117568e+18 1.7191872e+18 1.7257536e+18\n 1.7285185e+18 1.7206560e+18 1.7286912e+18 1.7019072e+18 1.7030304e+18\n 1.7181503e+18 1.7263585e+18 1.7221248e+18 1.7006976e+18 1.7132256e+18\n 1.7280863e+18 1.7275681e+18 1.7244575e+18 1.7130529e+18 1.7208287e+18\n 1.7151264e+18 1.7297281e+18 1.7294688e+18 1.7051039e+18 1.7029440e+18\n 1.7290367e+18 1.7094241e+18 1.7228160e+18 1.7125344e+18 1.7044128e+18\n 1.7260993e+18 1.7286048e+18 1.7312832e+18 1.7143488e+18 1.7178913e+18\n 1.7280000e+18 1.7110656e+18 1.7108064e+18 1.7072641e+18 1.7047584e+18\n 1.7043264e+18 1.7219520e+18 1.7313696e+18 1.7054496e+18 1.7213472e+18\n 1.7307648e+18 1.7140896e+18 1.7203968e+18 1.7242848e+18 1.7271360e+18\n 1.7005247e+18 1.7076096e+18 1.7064864e+18 1.7250624e+18 1.7222976e+18].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train a Random Forest Classifier\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model_product_type \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel_product_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Predict future product types\u001b[39;00m\n\u001b[1;32m     12\u001b[0m future_dates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m]), periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.7209152e+18 1.7165952e+18 1.7146944e+18 1.7174592e+18 1.7108927e+18\n 1.7260128e+18 1.7116704e+18 1.7025984e+18 1.7217791e+18 1.7098560e+18\n 1.7147807e+18 1.7202240e+18 1.7216928e+18 1.7203105e+18 1.7086464e+18\n 1.7248032e+18 1.7254944e+18 1.7007840e+18 1.7010432e+18 1.7074368e+18\n 1.7152992e+18 1.7113248e+18 1.7308512e+18 1.7283456e+18 1.7258400e+18\n 1.7236801e+18 1.7189280e+18 1.7300736e+18 1.7164225e+18 1.7121888e+18\n 1.7127072e+18 1.7305920e+18 1.7118433e+18 1.7104608e+18 1.7006112e+18\n 1.7053632e+18 1.7274816e+18 1.7196191e+18 1.7267040e+18 1.7082145e+18\n 1.7214336e+18 1.7233344e+18 1.7184960e+18 1.7161632e+18 1.7187552e+18\n 1.7231616e+18 1.7140033e+18 1.7159903e+18 1.7123615e+18 1.7229024e+18\n 1.7234208e+18 1.7122752e+18 1.7149536e+18 1.7083008e+18 1.7191009e+18\n 1.7119296e+18 1.7093376e+18 1.7057953e+18 1.7247168e+18 1.7299008e+18\n 1.7301600e+18 1.7309377e+18 1.7059680e+18 1.7089056e+18 1.7028576e+18\n 1.7186688e+18 1.7318880e+18 1.7256671e+18 1.7035488e+18 1.7078688e+18\n 1.7121023e+18 1.7134848e+18 1.7277408e+18 1.7045857e+18 1.7253216e+18\n 1.7200513e+18 1.7142625e+18 1.7112384e+18 1.7016480e+18 1.7145215e+18\n 1.7088192e+18 1.7251489e+18 1.7017343e+18 1.7013888e+18 1.7197056e+18\n 1.7107200e+18 1.7177184e+18 1.7126208e+18 1.7218656e+18 1.7092512e+18\n 1.7073504e+18 1.7291232e+18 1.7232479e+18 1.7269632e+18 1.7159040e+18\n 1.7057088e+18 1.7155584e+18 1.7310240e+18 1.7204832e+18 1.7279136e+18\n 1.7215201e+18 1.7055360e+18 1.7180640e+18 1.7199648e+18 1.7166817e+18\n 1.7051904e+18 1.7223840e+18 1.7004384e+18 1.7170272e+18 1.7267904e+18\n 1.7169407e+18 1.7171999e+18 1.7022528e+18 1.7111519e+18 1.7270496e+18\n 1.7311969e+18 1.7032032e+18 1.7302463e+18 1.7101152e+18 1.7100288e+18\n 1.7080416e+18 1.7201376e+18 1.7019936e+18 1.7011296e+18 1.7293824e+18\n 1.7172864e+18 1.7003520e+18 1.7288640e+18 1.7235072e+18 1.7205695e+18\n 1.7268767e+18 1.7282592e+18 1.7109792e+18 1.7050176e+18 1.7281728e+18\n 1.7252352e+18 1.7065728e+18 1.7207424e+18 1.7278271e+18 1.7284320e+18\n 1.7025120e+18 1.7063135e+18 1.7314559e+18 1.7152129e+18 1.7190144e+18\n 1.7241983e+18 1.7216064e+18 1.7292959e+18 1.7188417e+18 1.7296416e+18\n 1.7230752e+18 1.7299873e+18 1.7289504e+18 1.7031168e+18 1.7085600e+18\n 1.7129664e+18 1.7087327e+18 1.7171136e+18 1.7018208e+18 1.7162496e+18\n 1.7157311e+18 1.7156448e+18 1.7295552e+18 1.7090784e+18 1.7056224e+18\n 1.7102016e+18 1.7038943e+18 1.7114976e+18 1.7273089e+18 1.7066592e+18\n 1.7060545e+18 1.7024257e+18 1.7154721e+18 1.7075231e+18 1.7099423e+18\n 1.7211744e+18 1.7114112e+18 1.7070049e+18 1.7246304e+18 1.7077824e+18\n 1.7131392e+18 1.7194464e+18 1.7167680e+18 1.7076960e+18 1.7249760e+18\n 1.7127937e+18 1.7105472e+18 1.7083872e+18 1.7097696e+18 1.7318016e+18\n 1.7049312e+18 1.7179776e+18 1.7046720e+18 1.7081280e+18 1.7212609e+18\n 1.7173728e+18 1.7163360e+18 1.7084735e+18 1.7272224e+18 1.7014751e+18\n 1.7008704e+18 1.7276544e+18 1.7265312e+18 1.7243712e+18 1.7136576e+18\n 1.7042400e+18 1.7120160e+18 1.7160768e+18 1.7039808e+18 1.7192736e+18\n 1.7224705e+18 1.7158176e+18 1.7316288e+18 1.7168544e+18 1.7198784e+18\n 1.7238528e+18 1.7032896e+18 1.7117568e+18 1.7191872e+18 1.7257536e+18\n 1.7285185e+18 1.7206560e+18 1.7286912e+18 1.7019072e+18 1.7030304e+18\n 1.7181503e+18 1.7263585e+18 1.7221248e+18 1.7006976e+18 1.7132256e+18\n 1.7280863e+18 1.7275681e+18 1.7244575e+18 1.7130529e+18 1.7208287e+18\n 1.7151264e+18 1.7297281e+18 1.7294688e+18 1.7051039e+18 1.7029440e+18\n 1.7290367e+18 1.7094241e+18 1.7228160e+18 1.7125344e+18 1.7044128e+18\n 1.7260993e+18 1.7286048e+18 1.7312832e+18 1.7143488e+18 1.7178913e+18\n 1.7280000e+18 1.7110656e+18 1.7108064e+18 1.7072641e+18 1.7047584e+18\n 1.7043264e+18 1.7219520e+18 1.7313696e+18 1.7054496e+18 1.7213472e+18\n 1.7307648e+18 1.7140896e+18 1.7203968e+18 1.7242848e+18 1.7271360e+18\n 1.7005247e+18 1.7076096e+18 1.7064864e+18 1.7250624e+18 1.7222976e+18].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Prepare data for product type prediction\n",
    "X_product_type = data['TRACK_OUT_DATE']  # Add relevant features\n",
    "y_product_type = data['Car_Company']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_product_type, y_product_type, test_size=0.2)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model_product_type = RandomForestClassifier()\n",
    "model_product_type.fit(X_train, y_train)\n",
    "\n",
    "# Predict future product types\n",
    "future_dates = pd.date_range(start=max(data['TRACK_OUT_DATE']), periods=6, freq='M')\n",
    "future_data = pd.DataFrame({'TRACK_OUT_DATE': future_dates})\n",
    "future_predictions = model_product_type.predict(future_data)\n",
    "\n",
    "# Prepare data for yield rate prediction\n",
    "X_yield_rate = data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME']]\n",
    "y_yield_rate = data['YIELD_RATE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_yield_rate, y_yield_rate, test_size=0.2)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "model_yield_rate = RandomForestRegressor()\n",
    "model_yield_rate.fit(X_train, y_train)\n",
    "\n",
    "# Predict yield rates for future product types\n",
    "future_data['Car_Company'] = future_predictions\n",
    "future_yield_predictions = model_yield_rate.predict(future_data)\n",
    "\n",
    "# Combine predictions\n",
    "future_predictions_df = pd.DataFrame({'TRACK_OUT_DATE': future_dates,\n",
    "                                       'Car_Company': future_predictions,\n",
    "                                       'Predicted_Yield_Rate': future_yield_predictions})\n",
    "print(future_predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2682d895-b506-4731-835a-66bab3e1293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRACK_OUT_DATE    Car_Company  Predicted_Yield_Rate\n",
      "0     2024-11-30  Mercedes-Benz                0.7008\n",
      "1     2024-12-31  Mercedes-Benz                0.7008\n",
      "2     2025-01-31          Skoda                0.7008\n",
      "3     2025-02-28            BMW                0.7008\n",
      "4     2025-03-31           Saab                0.7008\n",
      "5     2025-04-30        Hyundai                0.7008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "# Feature preparation: Convert TRACK_OUT_DATE into useful numerical features\n",
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "data['Year'] = data['TRACK_OUT_DATE'].dt.year\n",
    "data['Month'] = data['TRACK_OUT_DATE'].dt.month\n",
    "X_product_type = data[['Year', 'Month']]  # Add other relevant features if available\n",
    "y_product_type = data['Car_Company']\n",
    "\n",
    "# Split and train the classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_product_type, y_product_type, test_size=0.2)\n",
    "model_product_type = RandomForestClassifier()\n",
    "model_product_type.fit(X_train, y_train)\n",
    "\n",
    "# Prepare future data with date features\n",
    "future_dates = pd.date_range(start=data['TRACK_OUT_DATE'].max(), periods=6, freq='M')\n",
    "future_data = pd.DataFrame({'TRACK_OUT_DATE': future_dates})\n",
    "future_data['Year'] = future_dates.year\n",
    "future_data['Month'] = future_dates.month\n",
    "\n",
    "# Predict future product types\n",
    "future_predictions = model_product_type.predict(future_data[['Year', 'Month']])\n",
    "\n",
    "# Prepare data for yield rate prediction (include more realistic values for features)\n",
    "# Example assumes mean values; adjust based on your data or add predictions from other models\n",
    "mean_values = data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME']].mean()\n",
    "future_data['DEFECT_COUNT'] = mean_values['DEFECT_COUNT']\n",
    "future_data['TEMPERATURE'] = mean_values['TEMPERATURE']\n",
    "future_data['HUMIDITY'] = mean_values['HUMIDITY']\n",
    "future_data['DOWNTIME'] = mean_values['DOWNTIME']\n",
    "future_data['Car_Company'] = future_predictions\n",
    "\n",
    "# Train the yield rate model\n",
    "X_yield_rate = data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME']]\n",
    "y_yield_rate = data['YIELD_RATE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_yield_rate, y_yield_rate, test_size=0.2)\n",
    "model_yield_rate = RandomForestRegressor()\n",
    "model_yield_rate.fit(X_train, y_train)\n",
    "\n",
    "# Predict yield rates for future product types\n",
    "future_yield_predictions = model_yield_rate.predict(future_data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME']])\n",
    "\n",
    "# Combine predictions\n",
    "future_predictions_df = pd.DataFrame({\n",
    "    'TRACK_OUT_DATE': future_dates,\n",
    "    'Car_Company': future_predictions,\n",
    "    'Predicted_Yield_Rate': future_yield_predictions\n",
    "})\n",
    "\n",
    "print(future_predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d096a16-5312-4a87-8232-dfbf53586f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rolls-Royce' 'Rolls-Royce' 'Saab' 'Saab' 'Seat' 'Skoda' 'Skoda' 'Skoda'\n",
      " 'Tesla' 'Tesla' 'Toyota' 'Vauxhall' 'Acura' 'Acura' 'Aston Martin' 'Audi'\n",
      " 'Bentley' 'Bentley' 'Bugatti' 'Bugatti' 'Cadillac' 'Cadillac' 'Chrysler'\n",
      " 'Chrysler' 'Daihatsu' 'Daihatsu' 'Fiat' 'Fiat' 'Ford' 'Genesis' 'GMC'\n",
      " 'Honda' 'Hummer' 'Hyundai' 'Infiniti' 'Isuzu' 'Jaguar' 'Jeep' 'Jeep'\n",
      " 'Jeep' 'Lexus' 'Lexus' 'Lincoln' 'Lucid Motors' 'Lucid Motors' 'Mazda'\n",
      " 'Mazda' 'Mercedes-Benz' 'Mercury' 'Mini' 'Mitsubishi' 'Nissan' 'Nissan'\n",
      " 'Opel' 'Peugeot' 'Plymouth' 'Polestar' 'Pontiac' 'Pontiac' 'Pontiac'\n",
      " 'Rolls-Royce' 'Rolls-Royce' 'Rolls-Royce' 'Saab' 'Saturn' 'Saturn'\n",
      " 'Skoda' 'Smart' 'Subaru' 'Subaru' 'Toyota' 'Toyota' 'Vauxhall'\n",
      " 'Volkswagen' 'Acura' 'Maserati' 'Aston Martin' 'Audi' 'Audi' 'BMW'\n",
      " 'Bugatti' 'Buick' 'Cadillac' 'Chevrolet' 'Chevrolet' 'Citroen' 'Daihatsu'\n",
      " 'Dodge' 'Ferrari' 'Ferrari' 'Ferrari' 'GMC' 'GMC' 'GMC' 'Hummer'\n",
      " 'Hyundai' 'Hyundai' 'Isuzu' 'Isuzu' 'Jeep' 'Kia' 'Lamborghini'\n",
      " 'Lucid Motors' 'Maserati' 'Mazda' 'McLaren' 'Mercedes-Benz' 'Mercury'\n",
      " 'Mini' 'Mini' 'Nissan' 'Nissan' 'Peugeot' 'Peugeot' 'Plymouth' 'Plymouth'\n",
      " 'Pontiac' 'Porsche' 'Ram Trucks' 'Renault' 'Rivian' 'Rolls-Royce' 'Saab'\n",
      " 'Saab' 'Skoda' 'Skoda' 'Smart' 'Subaru' 'Suzuki' 'Suzuki' 'Toyota'\n",
      " 'Vauxhall' 'Volkswagen' 'Acura' 'Alfa Romeo' 'Aston Martin' 'Audi'\n",
      " 'Bentley' 'Bentley' 'Bugatti' 'Buick' 'Cadillac' 'Chevrolet' 'Chevrolet'\n",
      " 'Daihatsu' 'Daihatsu' 'Dodge' 'Ferrari' 'Ferrari' 'Ford' 'Genesis' 'GMC'\n",
      " 'Honda' 'Hummer' 'Hyundai' 'Hyundai' 'Jaguar' 'Jaguar' 'Jeep' 'Suzuki'\n",
      " 'Lamborghini' 'Land Rover' 'Lexus' 'Lucid Motors' 'Maserati' 'Mazda'\n",
      " 'Audi' 'Mercury' 'Mercury' 'Mini' 'Mitsubishi' 'Nissan' 'Oldsmobile'\n",
      " 'Opel' 'Peugeot' 'Peugeot' 'Polestar' 'Pontiac' 'Porsche' 'Ram Trucks']\n"
     ]
    }
   ],
   "source": [
    "# Generate future daily dates for the next 6 months\n",
    "future_dates = pd.date_range(start=data['TRACK_OUT_DATE'].max() + pd.Timedelta(days=1), periods=180, freq='D')  # 180 days ≈ 6 months\n",
    "future_data = pd.DataFrame({'TRACK_OUT_DATE': future_dates})\n",
    "\n",
    "future_data['Month'] = future_dates.month\n",
    "future_data['Day'] = future_dates.day\n",
    "\n",
    "# Extract Year, Month, and Day features from TRACK_OUT_DATE\n",
    "data['Month'] = data['TRACK_OUT_DATE'].dt.month\n",
    "data['Day'] = data['TRACK_OUT_DATE'].dt.day  # Add Day feature\n",
    "\n",
    "X_product_type = data[['Month', 'Day']]  # Use all three features for training\n",
    "y_product_type = data['Car_Company']\n",
    "\n",
    "# Train the classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_product_type, y_product_type, test_size=0.2)\n",
    "model_product_type = RandomForestClassifier()\n",
    "model_product_type.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "future_predictions = model_product_type.predict(future_data[['Month','Day']])\n",
    "\n",
    "print(future_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5e0f9-30fd-4229-b69c-61eb73a54f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11c69072-9aac-4078-a8c2-d59f648d1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_yield_rate = data[['TRACK_OUT_DATE', 'Car_Company']].sort_values('TRACK_OUT_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8ef8e45-c139-4043-8df2-21d8bf37e493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRACK_OUT_DATE</th>\n",
       "      <th>Car_Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>Rivian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>Rolls-Royce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-11-21</td>\n",
       "      <td>Saab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2023-11-22</td>\n",
       "      <td>Saturn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>Seat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>Plymouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2024-11-15</td>\n",
       "      <td>Pontiac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-11-16</td>\n",
       "      <td>Porsche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2024-11-17</td>\n",
       "      <td>Ram Trucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>Renault</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TRACK_OUT_DATE  Car_Company\n",
       "308     2023-11-19       Rivian\n",
       "306     2023-11-20  Rolls-Royce\n",
       "12      2023-11-21         Saab\n",
       "148     2023-11-22       Saturn\n",
       "96      2023-11-23         Seat\n",
       "..             ...          ...\n",
       "100     2024-11-13     Plymouth\n",
       "332     2024-11-15      Pontiac\n",
       "9       2024-11-16      Porsche\n",
       "250     2024-11-17   Ram Trucks\n",
       "36      2024-11-18      Renault\n",
       "\n",
       "[338 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_yield_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78e526-4922-4e7b-b0de-2f7779c0ff91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d77dc7-fdc9-4fa9-bf3f-a52a8e3e07b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10265c8d-bfd4-438d-9cb3-a98fa6841012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Day_of_Year'] = data['TRACK_OUT_DATE'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bc77af3-2ad3-473b-96e7-87b107470b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      353\n",
       "1      204\n",
       "2       26\n",
       "3       41\n",
       "4       79\n",
       "      ... \n",
       "333    235\n",
       "334     53\n",
       "335    136\n",
       "336    232\n",
       "337     13\n",
       "Name: Day_of_Year, Length: 338, dtype: int32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Day_of_Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549ce87-fc26-4965-bc18-c09f8e249c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca01a353-0a3b-4280-b52d-ced8782dc9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRODUCT_ID', 'Car_Company', 'YIELD_RATE', 'SHIFT', 'MACHINE_ID',\n",
       "       'OPERATOR_ID', 'MATERIAL_BATCH', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME',\n",
       "       'DEFECT_COUNT', 'MAINTENANCE_SCHEDULE', 'TRACK_OUT_DATE',\n",
       "       'MANUFACTURE_DATE', 'MODEL_NAME', 'YEAR_OF_MANUFACTURE', 'ENGINE_TYPE',\n",
       "       'FUEL_TYPE', 'TRANSMISSION_TYPE', 'BODY_STYLE', 'Price', 'Mileage',\n",
       "       'SEATING_CAPACITY', 'COLOR_OPTIONS', 'SAFETY_FEATURES',\n",
       "       'Warranty_Period', 'Horsepower', 'Torque', 'Top_Speed', 'Acceleration',\n",
       "       'Dimensions', 'Weight', 'Fuel_Tank_Capacity', 'Year', 'Month', 'Day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41af6c6-9f81-4f41-8d35-60b7302477ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05641e71-733a-4fc4-a10a-751226e8c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Track_Out_Date Product_Type  Predicted_Yield_Rate\n",
      "0       2024-11-19        Lexus              0.693615\n",
      "1       2024-11-20        Lexus              0.621568\n",
      "2       2024-11-21        Lexus              0.549522\n",
      "3       2024-11-22        Lexus              0.549522\n",
      "4       2024-11-23        Lexus              0.597553\n",
      "..             ...          ...                   ...\n",
      "175     2025-05-13        Mazda              0.621314\n",
      "176     2025-05-14        Mazda              0.693360\n",
      "177     2025-05-15        Mazda              0.645329\n",
      "178     2025-05-16        Mazda              0.717376\n",
      "179     2025-05-17        Mazda              0.669345\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Convert 'Track_Out_Date' to datetime and extract numeric features (e.g., day of year)\n",
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "data['Day_of_Year'] = data['TRACK_OUT_DATE'].dt.dayofyear  # Use day of the year as a numeric feature\n",
    "\n",
    "# Prepare data for product type prediction\n",
    "X_product_type = data[['Day_of_Year']]\n",
    "y_product_type = data['Car_Company']\n",
    "\n",
    "# Encode 'Product_Type' if it's categorical\n",
    "label_encoder = LabelEncoder()\n",
    "y_product_type_encoded = label_encoder.fit_transform(y_product_type)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_product_type, y_product_type_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model_product_type = LogisticRegression(max_iter=1000)\n",
    "model_product_type.fit(X_train, y_train)\n",
    "\n",
    "# Predict future product types\n",
    "future_dates = pd.date_range(start=data['TRACK_OUT_DATE'].max() + pd.Timedelta(days=1), periods=180, freq='D')\n",
    "future_data = pd.DataFrame({'TRACK_OUT_DATE': future_dates})\n",
    "future_data['Day_of_Year'] = future_data['TRACK_OUT_DATE'].dt.dayofyear  # Prepare the same feature for prediction\n",
    "\n",
    "# Predict and decode future product types\n",
    "future_predictions_encoded = model_product_type.predict(future_data[['Day_of_Year']])\n",
    "future_predictions = label_encoder.inverse_transform(future_predictions_encoded)\n",
    "\n",
    "# Prepare data for yield rate prediction\n",
    "X_yield_rate = data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'Car_Company']]\n",
    "y_yield_rate = data['YIELD_RATE']\n",
    "\n",
    "# Encode 'Product_Type' in X if it's categorical\n",
    "X_yield_rate['Car_Company'] = label_encoder.transform(X_yield_rate['Car_Company'])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_yield_rate, y_yield_rate, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Linear Regression model for yield rates\n",
    "model_yield_rate = LinearRegression()\n",
    "model_yield_rate.fit(X_train, y_train)\n",
    "\n",
    "# Predict yield rates for future product types\n",
    "future_data['Car_Company'] = label_encoder.transform(future_predictions)\n",
    "# Placeholder: Ensure relevant features for yield rate prediction are present or forecasted\n",
    "future_data['DEFECT_COUNT'] = np.random.randint(1, 10, size=len(future_data))  # Replace with real or forecasted data\n",
    "future_data['TEMPERATURE'] = data['TEMPERATURE'].mean()\n",
    "future_data['HUMIDITY'] = data['HUMIDITY'].mean()\n",
    "future_data['DOWNTIME'] = data['DOWNTIME'].mean()\n",
    "\n",
    "# Predict future yield rates\n",
    "future_yield_predictions = model_yield_rate.predict(future_data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'Car_Company']])\n",
    "\n",
    "# Combine predictions into a DataFrame\n",
    "future_predictions_df = pd.DataFrame({\n",
    "    'Track_Out_Date': future_dates,\n",
    "    'Product_Type': future_predictions,\n",
    "    'Predicted_Yield_Rate': future_yield_predictions\n",
    "})\n",
    "\n",
    "print(future_predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ccaf187-2787-43c4-ba2e-34f37e173b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       2.0\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "           3       0.00      0.00      0.00       1.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00       2.0\n",
      "           7       0.00      0.00      0.00       1.0\n",
      "           8       0.00      0.00      0.00       2.0\n",
      "           9       0.00      0.00      0.00       2.0\n",
      "          10       0.00      0.00      0.00       2.0\n",
      "          11       0.00      0.00      0.00       0.0\n",
      "          12       0.00      0.00      0.00       1.0\n",
      "          13       0.00      0.00      0.00       1.0\n",
      "          15       0.00      0.00      0.00       0.0\n",
      "          16       0.00      0.00      0.00       2.0\n",
      "          17       0.00      0.00      0.00       2.0\n",
      "          18       0.00      0.00      0.00       2.0\n",
      "          19       0.00      0.00      0.00       1.0\n",
      "          20       0.00      0.00      0.00       3.0\n",
      "          21       0.00      0.00      0.00       1.0\n",
      "          22       0.00      0.00      0.00       0.0\n",
      "          23       0.00      0.00      0.00       1.0\n",
      "          24       0.00      0.00      0.00       0.0\n",
      "          25       0.00      0.00      0.00       2.0\n",
      "          26       0.00      0.00      0.00       1.0\n",
      "          27       0.00      0.00      0.00       2.0\n",
      "          28       0.00      0.00      0.00       1.0\n",
      "          29       0.00      0.00      0.00       0.0\n",
      "          31       0.00      0.00      0.00       1.0\n",
      "          32       0.00      0.00      0.00       1.0\n",
      "          33       0.00      0.00      0.00       0.0\n",
      "          34       0.00      0.00      0.00       2.0\n",
      "          35       0.00      0.00      0.00       3.0\n",
      "          36       0.00      0.00      0.00       2.0\n",
      "          37       0.00      0.00      0.00       1.0\n",
      "          38       0.00      0.00      0.00       2.0\n",
      "          39       0.00      0.00      0.00       1.0\n",
      "          40       0.00      0.00      0.00       1.0\n",
      "          41       0.00      0.00      0.00       1.0\n",
      "          42       0.00      0.00      0.00       1.0\n",
      "          43       0.00      0.00      0.00       1.0\n",
      "          44       0.00      0.00      0.00       2.0\n",
      "          45       0.00      0.00      0.00       0.0\n",
      "          46       0.00      0.00      0.00       1.0\n",
      "          47       0.00      0.00      0.00       0.0\n",
      "          48       0.00      0.00      0.00       2.0\n",
      "          50       0.00      0.00      0.00       0.0\n",
      "          51       0.00      0.00      0.00       3.0\n",
      "          52       0.00      0.00      0.00       0.0\n",
      "          53       0.00      0.00      0.00       2.0\n",
      "          54       0.00      0.00      0.00       1.0\n",
      "          55       0.00      0.00      0.00       3.0\n",
      "          56       0.00      0.00      0.00       0.0\n",
      "          57       0.00      0.00      0.00       1.0\n",
      "          59       0.00      0.00      0.00       1.0\n",
      "          60       0.00      0.00      0.00       2.0\n",
      "          61       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      68.0\n",
      "   macro avg       0.00      0.00      0.00      68.0\n",
      "weighted avg       0.00      0.00      0.00      68.0\n",
      "\n",
      "    TRACK_OUT_DATE Predicted_Car_Company\n",
      "0       2024-11-19           Rolls-Royce\n",
      "1       2024-11-20                  Saab\n",
      "2       2024-11-21                Saturn\n",
      "3       2024-11-22                  Seat\n",
      "4       2024-11-23                 Skoda\n",
      "..             ...                   ...\n",
      "175     2025-05-13               Pontiac\n",
      "176     2025-05-14               Pontiac\n",
      "177     2025-05-15               Pontiac\n",
      "178     2025-05-16               Pontiac\n",
      "179     2025-05-17               Porsche\n",
      "\n",
      "[180 rows x 2 columns]\n",
      "    Track_Out_Date Product_Type  Predicted_Yield_Rate\n",
      "0       2024-11-19  Rolls-Royce              0.644246\n",
      "1       2024-11-20         Saab              0.596151\n",
      "2       2024-11-21       Saturn              0.668134\n",
      "3       2024-11-22         Seat              0.692086\n",
      "4       2024-11-23        Skoda              0.740053\n",
      "..             ...          ...                   ...\n",
      "175     2025-05-13      Pontiac              0.716611\n",
      "176     2025-05-14      Pontiac              0.548502\n",
      "177     2025-05-15      Pontiac              0.740626\n",
      "178     2025-05-16      Pontiac              0.668580\n",
      "179     2025-05-17      Porsche              0.572454\n",
      "\n",
      "[180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load and preprocess data\n",
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "data['Day_of_Year'] = data['TRACK_OUT_DATE'].dt.dayofyear\n",
    "data['Month'] = data['TRACK_OUT_DATE'].dt.month  # Add Month feature\n",
    "data['Week'] = data['TRACK_OUT_DATE'].dt.isocalendar().week  # Add Week feature\n",
    "\n",
    "# Prepare data for product type prediction\n",
    "X_product_type = data[['Day_of_Year', 'Month', 'Week']]  # Use multiple temporal features\n",
    "y_product_type = data['Car_Company']\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_product_type_encoded = label_encoder.fit_transform(y_product_type)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_product_type, y_product_type_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier (better for handling categorical data and non-linearities)\n",
    "model_product_type = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_product_type.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model_product_type.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict future product types\n",
    "future_dates = pd.date_range(start=data['TRACK_OUT_DATE'].max() + pd.Timedelta(days=1), periods=180, freq='D')\n",
    "future_data = pd.DataFrame({'TRACK_OUT_DATE': future_dates})\n",
    "future_data['Day_of_Year'] = future_data['TRACK_OUT_DATE'].dt.dayofyear\n",
    "future_data['Month'] = future_data['TRACK_OUT_DATE'].dt.month\n",
    "future_data['Week'] = future_data['TRACK_OUT_DATE'].dt.isocalendar().week\n",
    "\n",
    "# Predict and decode future product types\n",
    "future_predictions_encoded = model_product_type.predict(future_data[['Day_of_Year', 'Month', 'Week']])\n",
    "future_predictions = label_encoder.inverse_transform(future_predictions_encoded)\n",
    "\n",
    "# Display future predictions\n",
    "future_data['Predicted_Car_Company'] = future_predictions\n",
    "print(future_data[['TRACK_OUT_DATE', 'Predicted_Car_Company']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare data for yield rate prediction\n",
    "X_yield_rate = data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'Car_Company']]\n",
    "y_yield_rate = data['YIELD_RATE']\n",
    "\n",
    "# Encode 'Product_Type' in X if it's categorical\n",
    "X_yield_rate['Car_Company'] = label_encoder.transform(X_yield_rate['Car_Company'])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_yield_rate, y_yield_rate, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Linear Regression model for yield rates\n",
    "model_yield_rate = LinearRegression()\n",
    "model_yield_rate.fit(X_train, y_train)\n",
    "\n",
    "# Predict yield rates for future product types\n",
    "future_data['Car_Company'] = label_encoder.transform(future_predictions)\n",
    "# Placeholder: Ensure relevant features for yield rate prediction are present or forecasted\n",
    "future_data['DEFECT_COUNT'] = np.random.randint(1, 10, size=len(future_data))  # Replace with real or forecasted data\n",
    "future_data['TEMPERATURE'] = data['TEMPERATURE'].mean()\n",
    "future_data['HUMIDITY'] = data['HUMIDITY'].mean()\n",
    "future_data['DOWNTIME'] = data['DOWNTIME'].mean()\n",
    "\n",
    "# Predict future yield rates\n",
    "future_yield_predictions = model_yield_rate.predict(future_data[['DEFECT_COUNT', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'Car_Company']])\n",
    "\n",
    "# Combine predictions into a DataFrame\n",
    "future_predictions_df = pd.DataFrame({\n",
    "    'Track_Out_Date': future_dates,\n",
    "    'Product_Type': future_predictions,\n",
    "    'Predicted_Yield_Rate': future_yield_predictions\n",
    "})\n",
    "\n",
    "print(future_predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de07261d-54d4-4599-996e-93f801dd9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_predictions_df.to_csv('future_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3454c6be-5980-44cb-a831-5a5362796058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "|\"Track_Out_Date\"     |\"Product_Type\"  |\"Predicted_Yield_Rate\"  |\n",
      "-----------------------------------------------------------------\n",
      "|2024-11-19 00:00:00  |Rolls-Royce     |0.6442458705467698      |\n",
      "|2024-11-20 00:00:00  |Saab            |0.5961511432987485      |\n",
      "|2024-11-21 00:00:00  |Saturn          |0.6681339345982323      |\n",
      "|2024-11-22 00:00:00  |Seat            |0.6920857184787141      |\n",
      "|2024-11-23 00:00:00  |Skoda           |0.7400530060686968      |\n",
      "|2024-11-24 00:00:00  |Smart           |0.7399892862396776      |\n",
      "|2024-11-25 00:00:00  |Suzuki          |0.6197843280341342      |\n",
      "|2024-11-26 00:00:00  |Suzuki          |0.5717533206151322      |\n",
      "|2024-11-27 00:00:00  |Tesla           |0.5957051044956139      |\n",
      "|2024-11-28 00:00:00  |Toyota          |0.6436723920855967      |\n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf_df = my_session.createDataFrame(future_predictions_df)\n",
    "sf_df.write.mode(\"overwrite\").save_as_table(\"future_predictions_df\")\n",
    "my_session.table(\"future_predictions_df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c18c4ec-bc93-4dd5-aa58-ae9df96a1b41",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, cross_val_score\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Add more temporal features\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay_of_Year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdayofyear\n\u001b[1;32m     15\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth  \u001b[38;5;66;03m# Add Month feature\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Add more temporal features\n",
    "\n",
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "data['Day_of_Year'] = data['TRACK_OUT_DATE'].dt.dayofyear\n",
    "data['Month'] = data['TRACK_OUT_DATE'].dt.month  # Add Month feature\n",
    "data['Week'] = data['TRACK_OUT_DATE'].dt.isocalendar().week  # Add Week feature\n",
    "data['Day_of_Week'] = data['TRACK_OUT_DATE'].dt.dayofweek\n",
    "data['Quarter'] = data['TRACK_OUT_DATE'].dt.quarter\n",
    "\n",
    "# Prepare data for product type prediction\n",
    "X_product_type = data[['Day_of_Year', 'Month', 'Week', 'Day_of_Week', 'Quarter']]\n",
    "y_product_type = data['Car_Company']\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_product_type_encoded = label_encoder.fit_transform(y_product_type)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_product_type, y_product_type_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict future product types\n",
    "future_dates = pd.date_range(start=data['TRACK_OUT_DATE'].max() + pd.Timedelta(days=1), periods=180, freq='D')\n",
    "future_data = pd.DataFrame({'TRACK_OUT_DATE': future_dates})\n",
    "future_data['Day_of_Year'] = future_data['TRACK_OUT_DATE'].dt.dayofyear\n",
    "future_data['Month'] = future_data['TRACK_OUT_DATE'].dt.month\n",
    "future_data['Week'] = future_data['TRACK_OUT_DATE'].dt.isocalendar().week\n",
    "future_data['Day_of_Week'] = future_data['TRACK_OUT_DATE'].dt.dayofweek\n",
    "future_data['Quarter'] = future_data['TRACK_OUT_DATE'].dt.quarter\n",
    "\n",
    "# Predict and decode future product types\n",
    "future_predictions_encoded = best_model.predict(future_data[['Day_of_Year', 'Month', 'Week', 'Day_of_Week', 'Quarter']])\n",
    "future_predictions = label_encoder.inverse_transform(future_predictions_encoded)\n",
    "\n",
    "# Display future predictions\n",
    "future_data['Predicted_Car_Company'] = future_predictions\n",
    "print(future_data[['TRACK_OUT_DATE', 'Predicted_Car_Company']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2056557-1878-42b5-8e0a-a46de2bd1718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
