{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1e6c24-963b-4340-b3ee-45864d3b53bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/8b/c640e4a243b59fc75e566ff3509ae55fb6cd4535643494be834c7d69c25d/statsmodels-0.14.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8MB 5.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<3,>=1.22.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (24.1)\n",
      "Collecting patsy>=0.5.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2b/b50d3d08ea0fc419c183a84210571eba005328efa62b6b98bc28e9ead32a/patsy-1.0.1-py2.py3-none-any.whl (232kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 98.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas!=2.1.0,>=1.4 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (2.2.0)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /opt/conda/lib/python3.9/site-packages (from statsmodels) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-1.0.1 statsmodels-0.14.4\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1bd77c-610f-4eea-9680-56fee7405e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbdd7521-2c0e-4920-ba21-01cbf6b9d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "223134ff-4fb5-49ca-b205-87a788dc35f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fosforml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/2e/3613fd0ccdbf3709dec86f87fe7624737a6f08bd1a813c88e65e7352dfde/fosforml-1.1.8-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==1.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/89/dce01a35d354159dcc901e3c7e7eb3fe98de5cb3639c6cd39518d8830caa/scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9MB 11.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle==2.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl\n",
      "Collecting snowflake-ml-python==1.5.0; python_version <= \"3.9\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/72/c0fa5a9bc811a59a5a1c7113ff89676ed1629d7d6463db8c1a8c97a8b5f6/snowflake_ml_python-1.5.0-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 78.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn==1.3.2->fosforml) (3.5.0)\n",
      "Requirement already satisfied: pandas<3,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.2.0)\n",
      "Collecting fsspec[http]<2024,>=2022.11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/25/fab23259a52ece5670dcb8452e1af34b89e6135ecc17cd4b54b4b479eac6/fsspec-2023.12.2-py3-none-any.whl (168kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 95.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting snowflake-snowpark-python!=1.12.0,<2,>=1.11.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/55/3cbf9670a6cc14690aa9c3cc279a5e6d8dc74ef2deb8ce6f8fb7d8268a35/snowflake_snowpark_python-1.25.0-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 75.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3fs<2024,>=2022.11\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/d6/b8a748b7d3fc7b0fd2ede1cf26a80281d65cc24d5d56b66c3a4c87e256e2/s3fs-2023.12.2-py3-none-any.whl\n",
      "Collecting packaging<24,>=20.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 18.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlparse<1,>=0.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/13/5f6654c9d915077fae255686ca6fa42095b62b7337e3e1aa9e82caa6f43a/sqlparse-0.5.2-py3-none-any.whl (44kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 26.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting retrying<2,>=1.3.3\n",
      "  Downloading https://files.pythonhosted.org/packages/8f/04/9e36f28be4c0532c0e9207ff9dc01fb13a2b0eb036476a213b0000837d0e/retrying-1.3.4-py3-none-any.whl\n",
      "Collecting xgboost<2,>=1.7.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/3a/c9c5d4d5c49b132ef15ac7b5ccf56ef1c82efe36cd19414771762e97c00e/xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3MB)\n",
      "\u001b[K     |████████████████████████████████| 200.3MB 128kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/19/1e47418efd3fadf343cc3c01703aba76e327e4f2224a1d137b7e2e5647ec/pyarrow-18.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.1MB)\n",
      "\u001b[K     |████████████████████████████████| 40.1MB 77.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytimeparse<2,>=1.1.8\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/b4/afd75551a3b910abd1d922dbd45e49e5deeb4d47dc50209ce489ba9844dd/pytimeparse-1.1.8-py2.py3-none-any.whl\n",
      "Collecting snowflake-connector-python[pandas]<4,>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/83/f8b30648768b33fa28786932164db320d9fce662dfe1cbd4c6031736b9b2/snowflake_connector_python-3.12.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 75.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py<2,>=0.15\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/87/de5c32fa1b1c6c3305d576e299801d8655c175ca9557019906247b994331/absl_py-1.4.0-py3-none-any.whl (126kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 117.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catboost<1.3,>=1.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/4a/8ada4fb635601943805cbeeb288f70982fefe48a7cef63352e318435aa98/catboost-1.2.7-cp39-cp39-manylinux2014_x86_64.whl (98.7MB)\n",
      "\u001b[K     |████████████████████████████████| 98.7MB 331kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (4.12.2)\n",
      "Collecting cachetools<6,>=3.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl\n",
      "Collecting importlib-resources<7,>=6.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl\n",
      "Collecting anyio<4,>=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl (80kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 34.1MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml<7,>=6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (6.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas<3,>=1.0.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas<3,>=1.0.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas<3,>=1.0.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.9.0.post0)\n",
      "Requirement already satisfied: requests; extra == \"http\" in /opt/conda/lib/python3.9/site-packages (from fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.32.3)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/61/a0515f4b71f91c0a3c54815d0e29f67932c1bc43ce75e703570eab21e011/aiohttp-3.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 82.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf<6,>=3.20\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/ae/3257b09328c0b4e59535e497b0c7537d4954038bdd53a2f0d2f49d15a7c4/protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 110.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python!=1.12.0,<2,>=1.11.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=40.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-snowpark-python!=1.12.0,<2,>=1.11.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (65.6.3)\n",
      "Collecting tzlocal\n",
      "  Downloading https://files.pythonhosted.org/packages/97/3f/c4c51c55ff8487f2e6d0e618dba917e3c3ee2caae6cf0fbb59c9b1876f2e/tzlocal-5.2-py3-none-any.whl\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/57/6402242dde160d9ef9903487b4277443dc3da04615f6c4d3b48564a8ab57/aiobotocore-2.15.2-py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 33.5MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from retrying<2,>=1.3.3->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.16.0)\n",
      "Collecting asn1crypto<2.0.0,>0.24.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/7f/09065fd9e27da0eda08b4d6897f1c13535066174cc023af248fc2a8d5e5a/asn1crypto-1.5.1-py2.py3-none-any.whl (105kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 121.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (42.0.5)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.16.0)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (24.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2024.7.4)\n",
      "Collecting sortedcontainers>=2.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl\n",
      "Collecting urllib3<2.0.0,>=1.21.1; python_version < \"3.10\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/cf/8435d5a7159e2a9c83a95896ed596f68cf798005fe107cc655b5c5c14704/urllib3-1.26.20-py2.py3-none-any.whl (144kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 123.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tomlkit\n",
      "  Downloading https://files.pythonhosted.org/packages/f9/b6/a447b5e4ec71e13871be01ba81f5dfc9d0af7e473da256ff46bc0e24026f/tomlkit-0.13.2-py3-none-any.whl\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (4.2.2)\n",
      "Collecting filelock<4,>=3.5\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/f8/feced7779d755758a52d1f6635d990b8d98dc0a29fa568bbe0625f18fdf3/filelock-3.16.1-py3-none-any.whl\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.7)\n",
      "Collecting pyjwt<3.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/79/84/0fdf9b18ba31d69877bd39c9cd6052b47f3761e9910c15de788e519f079f/PyJWT-2.9.0-py3-none-any.whl\n",
      "Collecting plotly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/ae/580600f441f6fc05218bd6c9d5794f4aef072a7d9093b291f1c50a9db8bc/plotly-5.24.1-py3-none-any.whl (19.1MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1MB 97.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/20/f56d5b88450593ccde3f283e338f3f976b2e479bddd9a147f14f66ee1ca7/matplotlib-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3MB)\n",
      "\u001b[K     |████████████████████████████████| 8.3MB 84.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting graphviz\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/be/d59db2d1d52697c6adc9eacaf50e8965b6345cc143f671e1ed068818d5cf/graphviz-0.20.3-py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 20.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /opt/conda/lib/python3.9/site-packages (from importlib-resources<7,>=6.1.1->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (3.19.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in /opt/conda/lib/python3.9/site-packages (from anyio<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (1.2.2)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl\n",
      "Collecting propcache>=0.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4e/97059dd24494d1c93d1efb98bb24825e1930265b41858dd59c15cb37a975/propcache-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 108.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1; extra == \"http\"->fsspec[http]<2024,>=2022.11->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (23.2.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/41/0d0fb18c1ad574f807196f5f3d99164edf9de3e169a58c6dc2d6ed5742b9/multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 81.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/d7/4b7877b277ba46dc571de11f0e9df9a9f3ea1548d6125b66541277b68e15/yarl-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 104.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d8/120cd0fe3e8530df0539e71ba9683eade12cae103dd7543e50d15f737917/aiohappyeyeballs-2.4.3-py3-none-any.whl\n",
      "Collecting async-timeout<6.0,>=4.0; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl\n",
      "Collecting frozenlist>=1.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/33/9f152105227630246135188901373c4f322cc026565ca6215b063f4c82f4/frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 105.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt<2.0.0,>=1.10.10\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/e7/459a8a4f40f2fa65eb73cb3f339e6d152957932516d18d0e996c7ae2d7ae/wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 31.8MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.35.37,>=1.35.16\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/60/056d58b606731f94fe395266c604ea9efcecc10e6857ceb9b10e6831d746/botocore-1.35.36-py3-none-any.whl (12.6MB)\n",
      "\u001b[K     |████████████████████████████████| 12.6MB 91.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aioitertools<1.0.0,>=0.5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/85/13/58b70a580de00893223d61de8fea167877a3aed97d4a5e1405c9159ef925/aioitertools-0.12.0-py3-none-any.whl\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]<4,>=3.5.0->snowflake-ml-python==1.5.0; python_version <= \"3.9\"->fosforml) (2.21)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl\n",
      "Collecting contourpy>=1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/11/57335544a3027e9b96a05948c32e566328e3a2f84b7b99a325b7a06d2b06/contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 113.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl\n",
      "Collecting kiwisolver>=1.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/b1/40655f6c3fa11ce740e8a964fa8e4c0479c87d6a7944b95af799c7a55dfe/kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 71.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/b1/c8f428bae932a27ce9c87e7b21aba8ea3e820aa11413c5a795868c37e039/pillow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3MB 77.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/3e/0841e7bf38ad317c960992dd03bac041899a1c21396013e6ddcfd2bc48c5/fonttools-4.55.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6MB 77.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/ec/2eb3cd785efd67806c46c13a17339708ddc346cbb684eade7a6e6f79536a/pyparsing-3.2.0-py3-none-any.whl (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 105.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/31/b4/b9b800c45527aadd64d5b442f9b932b00648617eb5d63d2c7a6587b7cafc/jmespath-1.0.1-py3-none-any.whl\n",
      "Installing collected packages: scikit-learn, cloudpickle, frozenlist, aiosignal, propcache, multidict, yarl, aiohappyeyeballs, async-timeout, aiohttp, fsspec, protobuf, asn1crypto, sortedcontainers, urllib3, tomlkit, packaging, filelock, pyjwt, pyarrow, snowflake-connector-python, tzlocal, snowflake-snowpark-python, wrapt, jmespath, botocore, aioitertools, aiobotocore, s3fs, sqlparse, retrying, xgboost, pytimeparse, absl-py, tenacity, plotly, contourpy, cycler, kiwisolver, pillow, importlib-resources, fonttools, pyparsing, matplotlib, graphviz, catboost, cachetools, anyio, snowflake-ml-python, fosforml\n",
      "  Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "  Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Found existing installation: anyio 4.4.0\n",
      "    Uninstalling anyio-4.4.0:\n",
      "      Successfully uninstalled anyio-4.4.0\n",
      "Successfully installed absl-py-1.4.0 aiobotocore-2.15.2 aiohappyeyeballs-2.4.3 aiohttp-3.11.2 aioitertools-0.12.0 aiosignal-1.3.1 anyio-3.7.1 asn1crypto-1.5.1 async-timeout-5.0.1 botocore-1.35.36 cachetools-5.5.0 catboost-1.2.7 cloudpickle-2.2.1 contourpy-1.3.0 cycler-0.12.1 filelock-3.16.1 fonttools-4.55.0 fosforml-1.1.8 frozenlist-1.5.0 fsspec-2023.12.2 graphviz-0.20.3 importlib-resources-6.4.5 jmespath-1.0.1 kiwisolver-1.4.7 matplotlib-3.9.2 multidict-6.1.0 packaging-23.2 pillow-11.0.0 plotly-5.24.1 propcache-0.2.0 protobuf-5.28.3 pyarrow-18.0.0 pyjwt-2.9.0 pyparsing-3.2.0 pytimeparse-1.1.8 retrying-1.3.4 s3fs-2023.12.2 scikit-learn-1.3.2 snowflake-connector-python-3.12.3 snowflake-ml-python-1.5.0 snowflake-snowpark-python-1.25.0 sortedcontainers-2.4.0 sqlparse-0.5.2 tenacity-9.0.0 tomlkit-0.13.2 tzlocal-5.2 urllib3-1.26.20 wrapt-1.16.0 xgboost-1.7.6 yarl-1.17.1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fosforml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed368029-8789-4bd2-b36d-fca71c9cc6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"HISTORICAL_YIELD_RATE\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "data = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "273a22e8-66d7-48e2-9eee-7e57c2a19212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached https://files.pythonhosted.org/packages/2a/9d/d332ec76e2cc442fce98bc43a44e69d3c281e6b4ede6b6db2616dc6fbec6/scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.19.5 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "\u001b[31mERROR: snowflake-ml-python 1.5.0 has requirement scikit-learn<1.4,>=1.2.1, but you'll have scikit-learn 1.5.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fosforml 1.1.8 has requirement scikit-learn==1.3.2, but you'll have scikit-learn 1.5.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 1.3.2\n",
      "    Uninstalling scikit-learn-1.3.2:\n",
      "      Successfully uninstalled scikit-learn-1.3.2\n",
      "Successfully installed scikit-learn-1.5.2\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb1a1f4-a12b-4a9e-a800-5c0c8faef02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80088aba-ea5d-43f8-9672-84db36739447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert YEAR_MONTH to datetime and extract features\n",
    "data['YEAR_MONTH'] = pd.to_datetime(data['YEAR_MONTH'])\n",
    "data['YEAR'] = data['YEAR_MONTH'].dt.year\n",
    "data['MONTH'] = data['YEAR_MONTH'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373b01ed-65ed-4c7c-9275-4b2f1ebd6a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for the training set: 0.003851\n",
      "RMSE for the training set: 0.084005\n",
      "Predicted Yield Rate for 2024-12 is 0.824527\n",
      "Predicted Yield Rate for 2025-01 is 0.806913\n",
      "Predicted Yield Rate for 2025-02 is 0.808377\n",
      "Predicted Yield Rate for 2025-03 is 0.809840\n",
      "Predicted Yield Rate for 2025-04 is 0.811304\n",
      "Predicted Yield Rate for 2025-05 is 0.812767\n",
      "Predicted Yield Rate for 2025-06 is 0.814231\n",
      "Predicted Yield Rate for 2025-07 is 0.815694\n",
      "Predicted Yield Rate for 2025-08 is 0.817158\n",
      "Predicted Yield Rate for 2025-09 is 0.818621\n",
      "Predicted Yield Rate for 2025-10 is 0.820085\n",
      "Predicted Yield Rate for 2025-11 is 0.821548\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset for training\n",
    "X = data[['YEAR', 'MONTH']]\n",
    "y = data['YIELD_RATE']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate R2 and RMSE for the training set\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "print(f\"R2 for the training set: {r2:.6f}\")\n",
    "print(f\"RMSE for the training set: {rmse:.6f}\")\n",
    "\n",
    "# Predict the yield rate for the next 1 year (12 months)\n",
    "future_dates = pd.date_range(start='2024-12-01', periods=12, freq='M')\n",
    "future_data = pd.DataFrame({'YEAR': future_dates.year, 'MONTH': future_dates.month})\n",
    "future_predictions = model.predict(future_data)\n",
    "\n",
    "# Print the predictions\n",
    "for date, prediction in zip(future_dates, future_predictions):\n",
    "    print(f\"Predicted Yield Rate for {date.strftime('%Y-%m')} is {prediction:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6d6f9ad-d35c-4b5d-bab7-3ede53017a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for the training set: 0.003851\n",
      "RMSE for the training set: 0.084005\n",
      "The predictions have been saved to 'predicted_yield_rates_all_products_single_model.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Prepare the dataset for training\n",
    "X = data[['YEAR', 'MONTH']]\n",
    "y = data['YIELD_RATE']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate R2 and RMSE for the training set\n",
    "r2 = r2_score(y_train, y_train_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "print(f\"R2 for the training set: {r2:.6f}\")\n",
    "print(f\"RMSE for the training set: {rmse:.6f}\")\n",
    "\n",
    "# Initialize a DataFrame to store all predictions\n",
    "all_predictions = pd.DataFrame()\n",
    "\n",
    "# Iterate over each product type to predict the yield rate for the next 1 year (12 months)\n",
    "for product in data['PRODUCT_TYPE'].unique():\n",
    "    # Predict the yield rate for the next 1 year (12 months)\n",
    "    future_dates = pd.date_range(start='2024-12-01', periods=12, freq='M')\n",
    "    future_data = pd.DataFrame({'YEAR': future_dates.year, 'MONTH': future_dates.month})\n",
    "    future_predictions = model.predict(future_data)\n",
    "    \n",
    "    # Store the predictions in a DataFrame\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'PRODUCT_TYPE': product,\n",
    "        'YEAR_MONTH': future_dates.strftime('%Y-%m'),\n",
    "        'PREDICTED_YIELD_RATE': future_predictions\n",
    "    })\n",
    "    \n",
    "    # Append the predictions to the all_predictions DataFrame\n",
    "    all_predictions = pd.concat([all_predictions, predictions_df], ignore_index=True)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "all_predictions.to_csv('predicted_yield_rates_all_products_single_model.csv', index=False)\n",
    "\n",
    "print(\"The predictions have been saved to 'predicted_yield_rates_all_products_single_model.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5628d138-06b7-4cf9-af14-75643904057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Acura, R2: 0.06653916013707695, RMSE: 0.08548674780963467\n",
      "Product: Alfa Romeo, R2: 0.15303447861533437, RMSE: 0.060360579685079095\n",
      "Product: Aston Martin, R2: 0.016093569007494146, RMSE: 0.07291780063150004\n",
      "Product: Audi, R2: 0.020453559786329012, RMSE: 0.07192073152826799\n",
      "Product: BMW, R2: 0.036344910057877655, RMSE: 0.06720704626269643\n",
      "Product: Bentley, R2: 0.0851273666666642, RMSE: 0.06902576901828013\n",
      "Product: Bugatti, R2: 0.01221422402468153, RMSE: 0.062180119719322496\n",
      "Product: Buick, R2: 0.05234923668136138, RMSE: 0.0835802840893066\n",
      "Product: Cadillac, R2: 0.005219453542069763, RMSE: 0.09195961476861012\n",
      "Product: Chevrolet, R2: 0.1253126728422439, RMSE: 0.07416506422650498\n",
      "Product: Chrysler, R2: 0.13340700395584892, RMSE: 0.07381643189248731\n",
      "Product: Citroen, R2: 0.14720624761507373, RMSE: 0.05985861441926206\n",
      "Product: Daihatsu, R2: 0.11938638248726907, RMSE: 0.07484837930254974\n",
      "Product: Dodge, R2: 0.005265504416486877, RMSE: 0.09468819161209076\n",
      "Product: Ferrari, R2: 0.10152296789975523, RMSE: 0.06366728028886379\n",
      "Product: Fiat, R2: 0.009095560720912887, RMSE: 0.06151888088152992\n",
      "Product: Ford, R2: 0.0597334094718871, RMSE: 0.06663033693488855\n",
      "Product: GMC, R2: 0.009119008219301339, RMSE: 0.07326905024229292\n",
      "Product: Genesis, R2: 0.11875389420406968, RMSE: 0.131689847211252\n",
      "Product: Honda, R2: 0.06346364878014665, RMSE: 0.0611525202261087\n",
      "Product: Hummer, R2: 0.16544958743673188, RMSE: 0.11009814875584296\n",
      "Product: Hyundai, R2: 0.015433040828677469, RMSE: 0.05650653899011407\n",
      "Product: Infiniti, R2: 0.04343529383560718, RMSE: 0.07714084771494634\n",
      "Product: Isuzu, R2: 0.04642685693716764, RMSE: 0.10425643441071661\n",
      "Product: Jaguar, R2: 0.13399068115973212, RMSE: 0.06140992207043266\n",
      "Product: Jeep, R2: 0.022841293425164833, RMSE: 0.09768593541146123\n",
      "Product: Kia, R2: 0.051546896601109116, RMSE: 0.06329257958010699\n",
      "Product: Lamborghini, R2: 6.564446935763968e-05, RMSE: 0.08402461107098001\n",
      "Product: Land Rover, R2: 0.0637327844980713, RMSE: 0.06091117746418644\n",
      "Product: Lexus, R2: 0.061647439827860695, RMSE: 0.055701367081430975\n",
      "Product: Lincoln, R2: 0.028986675052523392, RMSE: 0.09561401138515457\n",
      "Product: Lucid Motors, R2: 0.034914654667921985, RMSE: 0.10201747125208215\n",
      "Product: Maserati, R2: 0.43856544646145434, RMSE: 0.058435018587104356\n",
      "Product: Mazda, R2: 0.002229074552216659, RMSE: 0.0652329315259557\n",
      "Product: McLaren, R2: 0.0340654344043857, RMSE: 0.07711137600907889\n",
      "Product: Mercedes-Benz, R2: 0.008243837083972472, RMSE: 0.06727319279228795\n",
      "Product: Mercury, R2: 0.08782111168990325, RMSE: 0.0947903112576961\n",
      "Product: Mini, R2: 0.054285258027151784, RMSE: 0.07620873419728856\n",
      "Product: Mitsubishi, R2: 0.0028452772998184273, RMSE: 0.10533392728608597\n",
      "Product: Nissan, R2: 0.01837414264515491, RMSE: 0.06271564930885312\n",
      "Product: Oldsmobile, R2: 0.10046449627644538, RMSE: 0.09704481949618587\n",
      "Product: Opel, R2: 0.0036798210984068103, RMSE: 0.05641520204011934\n",
      "Product: Peugeot, R2: 0.0327662667642159, RMSE: 0.06320572962252818\n",
      "Product: Plymouth, R2: 0.2380856069709324, RMSE: 0.10097479133314763\n",
      "Product: Polestar, R2: 0.025924940228136628, RMSE: 0.09292683569098677\n",
      "Product: Pontiac, R2: 0.09349318059701905, RMSE: 0.09780475639583752\n",
      "Product: Porsche, R2: 0.0003977656394716922, RMSE: 0.06999556926533461\n",
      "Product: Ram Trucks, R2: 0.049857535071809456, RMSE: 0.09523711744530501\n",
      "Product: Renault, R2: 0.04696601985663906, RMSE: 0.0651533709537869\n",
      "Product: Rivian, R2: 0.14228867148517454, RMSE: 0.06936582238151208\n",
      "Product: Rolls-Royce, R2: 0.13722610055571127, RMSE: 0.08460249266960972\n",
      "Product: Saab, R2: 0.14503701520276424, RMSE: 0.079699269522534\n",
      "Product: Saturn, R2: 0.04626397623958167, RMSE: 0.09896314459348167\n",
      "Product: Seat, R2: 0.0406969196532917, RMSE: 0.0635970949173328\n",
      "Product: Skoda, R2: 0.003185626049204582, RMSE: 0.057704414753147824\n",
      "Product: Smart, R2: 0.006513890648953913, RMSE: 0.11317956562174937\n",
      "Product: Subaru, R2: 0.0678338069467036, RMSE: 0.04990336852185211\n",
      "Product: Suzuki, R2: 0.004517869695742527, RMSE: 0.09821051987202198\n",
      "Product: Tesla, R2: 0.01999902595724745, RMSE: 0.04443984023741808\n",
      "Product: Toyota, R2: 0.15702309815066184, RMSE: 0.0577345289268254\n",
      "Product: Vauxhall, R2: 0.03267579221742778, RMSE: 0.09024010738959638\n",
      "Product: Volkswagen, R2: 0.09043141415778688, RMSE: 0.06641804041221502\n",
      "Product: Volvo, R2: 0.08855774198018218, RMSE: 0.0680505276492033\n",
      "The predictions have been saved to 'predicted_yield_rates_all_products.csv'.\n",
      "The model metrics have been saved to 'model_metrics_all_products.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Convert YEAR_MONTH to datetime and extract features\n",
    "data['YEAR_MONTH'] = pd.to_datetime(data['YEAR_MONTH'])\n",
    "data['YEAR'] = data['YEAR_MONTH'].dt.year\n",
    "data['MONTH'] = data['YEAR_MONTH'].dt.month\n",
    "\n",
    "# Initialize a DataFrame to store all predictions\n",
    "all_predictions = pd.DataFrame()\n",
    "\n",
    "# Initialize a DataFrame to store all metrics\n",
    "all_metrics = pd.DataFrame(columns=['PRODUCT_TYPE', 'R2', 'RMSE'])\n",
    "\n",
    "# Iterate over each product type\n",
    "for product in data['PRODUCT_TYPE'].unique():\n",
    "    # Filter the data for the current product\n",
    "    product_data = data[data['PRODUCT_TYPE'] == product]\n",
    "    \n",
    "    # Prepare the dataset for training\n",
    "    X = product_data[['YEAR', 'MONTH']]\n",
    "    y = product_data['YIELD_RATE']\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create and train the linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    # Calculate R2 and RMSE for the training set\n",
    "    r2 = r2_score(y_train, y_train_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    \n",
    "    # Print the R2 and RMSE values for the current product\n",
    "    print(f'Product: {product}, R2: {r2}, RMSE: {rmse}')\n",
    "    \n",
    "    # Store the metrics in the DataFrame\n",
    "    all_metrics = pd.concat([all_metrics, pd.DataFrame({'PRODUCT_TYPE': [product], 'R2': [r2], 'RMSE': [rmse]})], ignore_index=True)\n",
    "    \n",
    "    # Predict the yield rate for the next 1 year (12 months)\n",
    "    future_dates = pd.date_range(start='2024-12-01', periods=12, freq='M')\n",
    "    future_data = pd.DataFrame({'YEAR': future_dates.year, 'MONTH': future_dates.month})\n",
    "    future_predictions = model.predict(future_data)\n",
    "    \n",
    "    # Store the predictions in a DataFrame\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'PRODUCT_TYPE': product,\n",
    "        'YEAR_MONTH': future_dates.strftime('%Y-%m'),\n",
    "        'PREDICTED_YIELD_RATE': future_predictions\n",
    "    })\n",
    "    \n",
    "    # Append the predictions to the all_predictions DataFrame\n",
    "    all_predictions = pd.concat([all_predictions, predictions_df], ignore_index=True)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "all_predictions.to_csv('predicted_yield_rates_all_products.csv', index=False)\n",
    "\n",
    "# Save the metrics to a CSV file\n",
    "all_metrics.to_csv('model_metrics_all_products.csv', index=False)\n",
    "\n",
    "print(\"The predictions have been saved to 'predicted_yield_rates_all_products.csv'.\")\n",
    "print(\"The model metrics have been saved to 'model_metrics_all_products.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "603cf07a-5e91-4397-b267-2adf7f63bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "446973a7-b1eb-4705-afe7-15e51f51edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"FACT_TABLE\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f650d2a-9c96-4ede-85f1-c2e9712ef813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: Acura | RMSE: 0.1240 | R2: -19.0118\n",
      "PRODUCT_TYPE: BMW | RMSE: 0.0477 | R2: 0.3090\n",
      "PRODUCT_TYPE: Bentley | RMSE: 0.4182 | R2: -36.8365\n",
      "PRODUCT_TYPE: Bugatti | RMSE: 0.1003 | R2: 0.0000\n",
      "PRODUCT_TYPE: Chevrolet | RMSE: 0.4972 | R2: -1097.7248\n",
      "PRODUCT_TYPE: Chrysler | RMSE: 0.1209 | R2: -3.0571\n",
      "PRODUCT_TYPE: Citroen | RMSE: 0.0496 | R2: 0.2659\n",
      "PRODUCT_TYPE: Daihatsu | RMSE: 1.0069 | R2: -3508.5969\n",
      "PRODUCT_TYPE: Dodge | RMSE: 0.1207 | R2: -1.9750\n",
      "PRODUCT_TYPE: Ferrari | RMSE: 0.0850 | R2: -0.7117\n",
      "PRODUCT_TYPE: Ford | RMSE: 0.0905 | R2: 0.0000\n",
      "PRODUCT_TYPE: Genesis | RMSE: 0.0920 | R2: -2.1711\n",
      "PRODUCT_TYPE: Honda | RMSE: 0.1547 | R2: -10.8288\n",
      "PRODUCT_TYPE: Hyundai | RMSE: 3.3248 | R2: -4828.4290\n",
      "PRODUCT_TYPE: Infiniti | RMSE: 0.0315 | R2: 0.4694\n",
      "PRODUCT_TYPE: Jaguar | RMSE: 0.1506 | R2: -11.8290\n",
      "PRODUCT_TYPE: Kia | RMSE: 0.0600 | R2: -1.2498\n",
      "PRODUCT_TYPE: Lamborghini | RMSE: 0.2179 | R2: -6.4194\n",
      "PRODUCT_TYPE: Land Rover | RMSE: 0.1812 | R2: -25.8137\n",
      "PRODUCT_TYPE: Lexus | RMSE: 0.1410 | R2: -2.5716\n",
      "PRODUCT_TYPE: Lincoln | RMSE: 0.1427 | R2: -5.2358\n",
      "PRODUCT_TYPE: Lucid Motors | RMSE: 0.1672 | R2: -278.4025\n",
      "PRODUCT_TYPE: Maserati | RMSE: 0.0759 | R2: -0.5064\n",
      "PRODUCT_TYPE: Mazda | RMSE: 0.0464 | R2: nan\n",
      "PRODUCT_TYPE: McLaren | RMSE: 0.0872 | R2: -10.0463\n",
      "PRODUCT_TYPE: Mercedes-Benz | RMSE: 0.0969 | R2: -1.1240\n",
      "PRODUCT_TYPE: Mini | RMSE: 0.1322 | R2: -2.0729\n",
      "PRODUCT_TYPE: Mitsubishi | RMSE: 0.1868 | R2: 0.0000\n",
      "PRODUCT_TYPE: Nissan | RMSE: 0.1387 | R2: -4.5467\n",
      "PRODUCT_TYPE: Oldsmobile | RMSE: 0.1200 | R2: nan\n",
      "PRODUCT_TYPE: Peugeot | RMSE: 0.1216 | R2: -3.7866\n",
      "PRODUCT_TYPE: Plymouth | RMSE: 0.1114 | R2: -18.9561\n",
      "PRODUCT_TYPE: Polestar | RMSE: 0.1454 | R2: -29.6912\n",
      "PRODUCT_TYPE: Pontiac | RMSE: 0.1938 | R2: -40.7527\n",
      "PRODUCT_TYPE: Porsche | RMSE: 0.1251 | R2: -5.3403\n",
      "PRODUCT_TYPE: Renault | RMSE: 0.1328 | R2: -2.2944\n",
      "PRODUCT_TYPE: Rivian | RMSE: 0.0836 | R2: -0.4424\n",
      "PRODUCT_TYPE: Saturn | RMSE: 0.1997 | R2: -596.9036\n",
      "PRODUCT_TYPE: Seat | RMSE: 0.2915 | R2: -122.3081\n",
      "PRODUCT_TYPE: Skoda | RMSE: 0.3674 | R2: -29.5169\n",
      "PRODUCT_TYPE: Subaru | RMSE: 0.2383 | R2: -62.1129\n",
      "PRODUCT_TYPE: Suzuki | RMSE: 0.1141 | R2: -7.1425\n",
      "PRODUCT_TYPE: Toyota | RMSE: 0.1288 | R2: -5.7246\n",
      "PRODUCT_TYPE: Volkswagen | RMSE: 0.2962 | R2: -3508.7163\n",
      "PRODUCT_TYPE: Volvo | RMSE: 0.0650 | R2: -0.0271\n",
      "\n",
      "Forecast Results:\n",
      "     PRODUCT_TYPE TRACK_OUT_DATE  PREDICTED_YIELD_RATE\n",
      "0           Acura     2024-11-16              0.832556\n",
      "1           Acura     2024-12-16              1.508122\n",
      "2           Acura     2025-01-15              1.849073\n",
      "3           Acura     2025-02-14             -0.192072\n",
      "4           Acura     2025-03-16              0.111748\n",
      "...           ...            ...                   ...\n",
      "1075        Volvo     2026-07-10              1.381476\n",
      "1076        Volvo     2026-08-09              1.846795\n",
      "1077        Volvo     2026-09-08              2.074770\n",
      "1078        Volvo     2026-10-08              1.992810\n",
      "1079        Volvo     2026-11-07              1.680789\n",
      "\n",
      "[1080 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to train a single model and forecast for each product type\n",
    "def train_and_forecast_yield(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "\n",
    "# Forecast Yield Rates\n",
    "forecast_df = train_and_forecast_yield(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "    # Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81a96500-5ecb-4218-a793-cec9f7aafb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4f9ced5-3847-4d34-b52a-365a936aae0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "sklearn needs to be installed in order to use this module",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 85\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast_df\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# Forecast Yield Rates using XGBoost\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_forecast_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Save or display the forecast results\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecast Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 44\u001b[0m, in \u001b[0;36mtrain_and_forecast_xgboost\u001b[0;34m(data, forecast_years, num_lags)\u001b[0m\n\u001b[1;32m     41\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Train the XGBoost model\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mXGBRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1691\u001b[0m, in \u001b[0;36mXGBRegressor.__init__\u001b[0;34m(self, objective, **kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   1689\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, objective: _SklObjective \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1690\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1691\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:584\u001b[0m, in \u001b[0;36mXGBModel.__init__\u001b[0;34m(self, max_depth, max_leaves, max_bin, grow_policy, learning_rate, n_estimators, verbosity, objective, booster, tree_method, n_jobs, gamma, min_child_weight, max_delta_step, subsample, sampling_method, colsample_bytree, colsample_bylevel, colsample_bynode, reg_alpha, reg_lambda, scale_pos_weight, base_score, random_state, missing, num_parallel_tree, monotone_constraints, interaction_constraints, importance_type, gpu_id, validate_parameters, predictor, enable_categorical, feature_types, max_cat_to_onehot, max_cat_threshold, eval_metric, early_stopping_rounds, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    542\u001b[0m     max_depth: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SKLEARN_INSTALLED:\n\u001b[0;32m--> 584\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn needs to be installed in order to use this module\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators \u001b[38;5;241m=\u001b[39m n_estimators\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m objective\n",
      "\u001b[0;31mImportError\u001b[0m: sklearn needs to be installed in order to use this module"
     ]
    }
   ],
   "source": [
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using XGBoost\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "    # Forecast Yield Rates using XGBoost\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "    # Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2d57389-2074-4195-9c58-9fb2e02a9ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.9/site-packages (1.7.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "750b1f7e-d3dd-4f81-a75c-3efc36189953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (1.5.2)\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.9/site-packages (1.7.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (1.26.4)\n",
      "Collecting openpyxl\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/da/977ded879c29cbd04de313843e76868e6e13408a94ed6b987245dc7c8506/openpyxl-3.1.5-py2.py3-none-any.whl (250kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Collecting et-xmlfile\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/8b/5fe2cc11fee489817272089c4203e679c63b570a5aaeb18d852ae3cbba6a/et_xmlfile-2.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn xgboost pandas numpy openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2f8995-0913-4378-b8c6-2bc5fad9d218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: Acura | RMSE: 0.0937 | R2: -10.4196\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 91\u001b[0m\n\u001b[1;32m     87\u001b[0m     forecast_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(forecast_results)\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast_df\n\u001b[0;32m---> 91\u001b[0m forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_forecast_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Save or display the forecast results\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecast Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 72\u001b[0m, in \u001b[0;36mtrain_and_forecast_xgboost\u001b[0;34m(data, forecast_years, num_lags)\u001b[0m\n\u001b[1;32m     68\u001b[0m future_forecast \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m future_dates:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Predict the next yield rate\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     predicted_yield \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_known_values\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m     future_forecast\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m: product_type,\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICTED_YIELD_RATE\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_yield\n\u001b[1;32m     77\u001b[0m     })\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Update the lag values for the next iteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1139\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m test \u001b[38;5;241m=\u001b[39m DMatrix(\n\u001b[1;32m   1132\u001b[0m     X,\n\u001b[1;32m   1133\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[1;32m   1138\u001b[0m )\n\u001b[0;32m-> 1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2137\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpecting data to be a DMatrix object, got: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(data))\n\u001b[1;32m   2136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m-> 2137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dmatrix_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2138\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\u001b[38;5;28mself\u001b[39m, ntree_limit, iteration_range)\n\u001b[1;32m   2139\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: training,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m: strict_shape,\n\u001b[1;32m   2145\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2747\u001b[0m, in \u001b[0;36mBooster._validate_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;241m=\u001b[39m ft\n\u001b[0;32m-> 2747\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2754\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2755\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2756\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m   2757\u001b[0m     )\n\u001b[1;32m   2759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m!=\u001b[39m feature_names:\n\u001b[1;32m   2760\u001b[0m     dat_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(cast(FeatureNames, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m   2761\u001b[0m         cast(FeatureNames, feature_names)\n\u001b[1;32m   2762\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using XGBoost\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "    # Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bc4e46d-bf80-45b9-9f7a-9a998b00f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/7d/500c9ad20238fcfcb4cb9243eede163594d7020ce87bd9610c9e02771876/pip-24.3.1-py3-none-any.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-24.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400f6d84-bf08-4254-b33d-e61ebb7ab753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"FACT_TABLE\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7541ea67-ca00-441a-81e8-9bf86fbe2eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: Acura | RMSE: 0.1240 | R2: -19.0118\n",
      "PRODUCT_TYPE: BMW | RMSE: 0.0477 | R2: 0.3090\n",
      "PRODUCT_TYPE: Bentley | RMSE: 0.4182 | R2: -36.8365\n",
      "PRODUCT_TYPE: Bugatti | RMSE: 0.1003 | R2: 0.0000\n",
      "PRODUCT_TYPE: Chevrolet | RMSE: 0.4972 | R2: -1097.7248\n",
      "PRODUCT_TYPE: Chrysler | RMSE: 0.1209 | R2: -3.0571\n",
      "PRODUCT_TYPE: Citroen | RMSE: 0.0496 | R2: 0.2659\n",
      "PRODUCT_TYPE: Daihatsu | RMSE: 1.0069 | R2: -3508.5969\n",
      "PRODUCT_TYPE: Dodge | RMSE: 0.1207 | R2: -1.9750\n",
      "PRODUCT_TYPE: Ferrari | RMSE: 0.0850 | R2: -0.7117\n",
      "PRODUCT_TYPE: Ford | RMSE: 0.0905 | R2: 0.0000\n",
      "PRODUCT_TYPE: Genesis | RMSE: 0.0920 | R2: -2.1711\n",
      "PRODUCT_TYPE: Honda | RMSE: 0.1547 | R2: -10.8288\n",
      "PRODUCT_TYPE: Hyundai | RMSE: 3.3248 | R2: -4828.4290\n",
      "PRODUCT_TYPE: Infiniti | RMSE: 0.0315 | R2: 0.4694\n",
      "PRODUCT_TYPE: Jaguar | RMSE: 0.1506 | R2: -11.8290\n",
      "PRODUCT_TYPE: Kia | RMSE: 0.0600 | R2: -1.2498\n",
      "PRODUCT_TYPE: Lamborghini | RMSE: 0.2179 | R2: -6.4194\n",
      "PRODUCT_TYPE: Land Rover | RMSE: 0.1812 | R2: -25.8137\n",
      "PRODUCT_TYPE: Lexus | RMSE: 0.1410 | R2: -2.5716\n",
      "PRODUCT_TYPE: Lincoln | RMSE: 0.1427 | R2: -5.2358\n",
      "PRODUCT_TYPE: Lucid Motors | RMSE: 0.1672 | R2: -278.4025\n",
      "PRODUCT_TYPE: Maserati | RMSE: 0.0759 | R2: -0.5064\n",
      "PRODUCT_TYPE: Mazda | RMSE: 0.0464 | R2: nan\n",
      "PRODUCT_TYPE: McLaren | RMSE: 0.0872 | R2: -10.0463\n",
      "PRODUCT_TYPE: Mercedes-Benz | RMSE: 0.0969 | R2: -1.1240\n",
      "PRODUCT_TYPE: Mini | RMSE: 0.1322 | R2: -2.0729\n",
      "PRODUCT_TYPE: Mitsubishi | RMSE: 0.1868 | R2: 0.0000\n",
      "PRODUCT_TYPE: Nissan | RMSE: 0.1387 | R2: -4.5467\n",
      "PRODUCT_TYPE: Oldsmobile | RMSE: 0.1200 | R2: nan\n",
      "PRODUCT_TYPE: Peugeot | RMSE: 0.1216 | R2: -3.7866\n",
      "PRODUCT_TYPE: Plymouth | RMSE: 0.1114 | R2: -18.9561\n",
      "PRODUCT_TYPE: Polestar | RMSE: 0.1454 | R2: -29.6912\n",
      "PRODUCT_TYPE: Pontiac | RMSE: 0.1938 | R2: -40.7527\n",
      "PRODUCT_TYPE: Porsche | RMSE: 0.1251 | R2: -5.3403\n",
      "PRODUCT_TYPE: Renault | RMSE: 0.1328 | R2: -2.2944\n",
      "PRODUCT_TYPE: Rivian | RMSE: 0.0836 | R2: -0.4424\n",
      "PRODUCT_TYPE: Saturn | RMSE: 0.1997 | R2: -596.9036\n",
      "PRODUCT_TYPE: Seat | RMSE: 0.2915 | R2: -122.3081\n",
      "PRODUCT_TYPE: Skoda | RMSE: 0.3674 | R2: -29.5169\n",
      "PRODUCT_TYPE: Subaru | RMSE: 0.2383 | R2: -62.1129\n",
      "PRODUCT_TYPE: Suzuki | RMSE: 0.1141 | R2: -7.1425\n",
      "PRODUCT_TYPE: Toyota | RMSE: 0.1288 | R2: -5.7246\n",
      "PRODUCT_TYPE: Volkswagen | RMSE: 0.2962 | R2: -3508.7163\n",
      "PRODUCT_TYPE: Volvo | RMSE: 0.0650 | R2: -0.0271\n",
      "\n",
      "Forecast Results:\n",
      "     PRODUCT_TYPE TRACK_OUT_DATE  PREDICTED_YIELD_RATE\n",
      "0           Acura     2024-11-16              0.832556\n",
      "1           Acura     2024-12-16              1.508122\n",
      "2           Acura     2025-01-15              1.849073\n",
      "3           Acura     2025-02-14             -0.192072\n",
      "4           Acura     2025-03-16              0.111748\n",
      "...           ...            ...                   ...\n",
      "1075        Volvo     2026-07-10              1.381476\n",
      "1076        Volvo     2026-08-09              1.846795\n",
      "1077        Volvo     2026-09-08              2.074770\n",
      "1078        Volvo     2026-10-08              1.992810\n",
      "1079        Volvo     2026-11-07              1.680789\n",
      "\n",
      "[1080 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using Linear Regression\n",
    "def train_and_forecast_linear_regression(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the Linear Regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "# Assuming df is your DataFrame loaded from the CSV file.\n",
    "# df = pd.read_csv('2024-11-15 11_38am (2).csv')  # Uncomment this line to load your dataset\n",
    "\n",
    "# For demonstration purposes, let's create a sample DataFrame similar to your description.\n",
    "\n",
    "\n",
    "#df_sample = pd.DataFrame(data_sample)\n",
    "\n",
    "forecast_df = train_and_forecast_linear_regression(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "# Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5687c6-673b-48cc-858b-1207155e3a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: Acura | RMSE: 0.0937 | R2: -10.4196\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 98\u001b[0m\n\u001b[1;32m     93\u001b[0m     forecast_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(forecast_results)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast_df\n\u001b[0;32m---> 98\u001b[0m forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_forecast_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Save or display the forecast results\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecast Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 78\u001b[0m, in \u001b[0;36mtrain_and_forecast_xgboost\u001b[0;34m(data, forecast_years, num_lags)\u001b[0m\n\u001b[1;32m     74\u001b[0m future_forecast \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m future_dates:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# Predict the next yield rate\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     predicted_yield \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_known_values\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     79\u001b[0m     future_forecast\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m: product_type,\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICTED_YIELD_RATE\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_yield\n\u001b[1;32m     83\u001b[0m     })\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# Update the lag values for the next iteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1139\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m test \u001b[38;5;241m=\u001b[39m DMatrix(\n\u001b[1;32m   1132\u001b[0m     X,\n\u001b[1;32m   1133\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[1;32m   1138\u001b[0m )\n\u001b[0;32m-> 1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2137\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpecting data to be a DMatrix object, got: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(data))\n\u001b[1;32m   2136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m-> 2137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dmatrix_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2138\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\u001b[38;5;28mself\u001b[39m, ntree_limit, iteration_range)\n\u001b[1;32m   2139\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: training,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m: strict_shape,\n\u001b[1;32m   2145\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2747\u001b[0m, in \u001b[0;36mBooster._validate_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;241m=\u001b[39m ft\n\u001b[0;32m-> 2747\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2754\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2755\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2756\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m   2757\u001b[0m     )\n\u001b[1;32m   2759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m!=\u001b[39m feature_names:\n\u001b[1;32m   2760\u001b[0m     dat_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(cast(FeatureNames, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m   2761\u001b[0m         cast(FeatureNames, feature_names)\n\u001b[1;32m   2762\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using XGBoost\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "    # Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf9c31cc-6941-46aa-b0a1-6d0e5f39c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created lag column: YIELD_RATE_Lag_1\n",
      "Created lag column: YIELD_RATE_Lag_2\n",
      "Created lag column: YIELD_RATE_Lag_3\n",
      "\n",
      "Columns after creating lag features:\n",
      "Index(['PRODUCT_ID', 'PRODUCT_TYPE', 'YIELD_RATE', 'SHIFT', 'MACHINE_ID',\n",
      "       'OPERATOR_ID', 'MATERIAL_BATCH', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME',\n",
      "       'DEFECT_COUNT', 'MAINTENANCE_SCHEDULE', 'TRACK_OUT_DATE',\n",
      "       'MANUFACTURE_DATE', 'MODEL_NAME', 'YEAR_OF_MANUFACTURE', 'ENGINE_TYPE',\n",
      "       'FUEL_TYPE', 'TRANSMISSION_TYPE', 'BODY_STYLE', 'Price(in Dollars)',\n",
      "       'Mileage (km/l or mpg)', 'SEATING_CAPACITY', 'COLOR_OPTIONS',\n",
      "       'SAFETY_FEATURES', 'Warranty Period(in Years)', 'Horsepower (HP)',\n",
      "       'Torque (Nm)', 'Top Speed (km/h or mph)',\n",
      "       'Acceleration (0-100 km/h or 0-60 mph)', 'Dimensions (L x W x H)',\n",
      "       'Weight (kg or lbs)', 'Fuel Tank Capacity (liters)', 'YIELD_RATE_Lag_1',\n",
      "       'YIELD_RATE_Lag_2', 'YIELD_RATE_Lag_3'],\n",
      "      dtype='object')\n",
      "\n",
      "Size of data after dropping NaN values: (528, 36)\n",
      "\n",
      "Sample SHIFT_ENC values:\n",
      "         SHIFT  SHIFT_ENC\n",
      "44       Night          2\n",
      "65     Morning          1\n",
      "118  Afternoon          0\n",
      "PRODUCT_TYPE: Acura | RMSE: 0.0937 | R2: -10.4196\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 108\u001b[0m\n\u001b[1;32m    103\u001b[0m     forecast_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(forecast_results)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast_df\n\u001b[0;32m--> 108\u001b[0m forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_forecast_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# Save or display the forecast results\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecast Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 88\u001b[0m, in \u001b[0;36mtrain_and_forecast_xgboost\u001b[0;34m(data, forecast_years, num_lags)\u001b[0m\n\u001b[1;32m     84\u001b[0m future_forecast \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m future_dates:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Predict the next yield rate\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     predicted_yield \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_known_values\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     89\u001b[0m     future_forecast\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m: product_type,\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICTED_YIELD_RATE\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_yield\n\u001b[1;32m     93\u001b[0m     })\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# Update the lag values for the next iteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1139\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m test \u001b[38;5;241m=\u001b[39m DMatrix(\n\u001b[1;32m   1132\u001b[0m     X,\n\u001b[1;32m   1133\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[1;32m   1138\u001b[0m )\n\u001b[0;32m-> 1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2137\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpecting data to be a DMatrix object, got: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(data))\n\u001b[1;32m   2136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m-> 2137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dmatrix_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2138\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\u001b[38;5;28mself\u001b[39m, ntree_limit, iteration_range)\n\u001b[1;32m   2139\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: training,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m: strict_shape,\n\u001b[1;32m   2145\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2747\u001b[0m, in \u001b[0;36mBooster._validate_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;241m=\u001b[39m ft\n\u001b[0;32m-> 2747\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2754\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2755\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2756\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m   2757\u001b[0m     )\n\u001b[1;32m   2759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m!=\u001b[39m feature_names:\n\u001b[1;32m   2760\u001b[0m     dat_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(cast(FeatureNames, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m   2761\u001b[0m         cast(FeatureNames, feature_names)\n\u001b[1;32m   2762\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC"
     ]
    }
   ],
   "source": [
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        lag_column_name = f'{column}_Lag_{lag}'\n",
    "        data[lag_column_name] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "        print(f\"Created lag column: {lag_column_name}\")\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using XGBoost\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Debug: Check if lag features were created\n",
    "    print(\"\\nColumns after creating lag features:\")\n",
    "    print(data.columns)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Debug: Check the size of data after dropping NaNs\n",
    "    print(\"\\nSize of data after dropping NaN values:\", data.shape)\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Debug: Check if SHIFT_ENC column is created\n",
    "    print(\"\\nSample SHIFT_ENC values:\")\n",
    "    print(data[['SHIFT', 'SHIFT_ENC']].drop_duplicates())\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Debug: Verify that all required columns are present in the DataFrame\n",
    "    missing_features = [col for col in feature_columns if col not in data.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing features in the DataFrame: {missing_features}\")\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "    # Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eebc0273-c128-469d-bb72-937635287e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created lag column: YIELD_RATE_Lag_1\n",
      "Created lag column: YIELD_RATE_Lag_2\n",
      "Created lag column: YIELD_RATE_Lag_3\n",
      "\n",
      "Columns after creating lag features:\n",
      "Index(['PRODUCT_ID', 'PRODUCT_TYPE', 'YIELD_RATE', 'SHIFT', 'MACHINE_ID',\n",
      "       'OPERATOR_ID', 'MATERIAL_BATCH', 'TEMPERATURE', 'HUMIDITY', 'DOWNTIME',\n",
      "       'DEFECT_COUNT', 'MAINTENANCE_SCHEDULE', 'TRACK_OUT_DATE',\n",
      "       'MANUFACTURE_DATE', 'MODEL_NAME', 'YEAR_OF_MANUFACTURE', 'ENGINE_TYPE',\n",
      "       'FUEL_TYPE', 'TRANSMISSION_TYPE', 'BODY_STYLE', 'Price(in Dollars)',\n",
      "       'Mileage (km/l or mpg)', 'SEATING_CAPACITY', 'COLOR_OPTIONS',\n",
      "       'SAFETY_FEATURES', 'Warranty Period(in Years)', 'Horsepower (HP)',\n",
      "       'Torque (Nm)', 'Top Speed (km/h or mph)',\n",
      "       'Acceleration (0-100 km/h or 0-60 mph)', 'Dimensions (L x W x H)',\n",
      "       'Weight (kg or lbs)', 'Fuel Tank Capacity (liters)', 'YIELD_RATE_Lag_1',\n",
      "       'YIELD_RATE_Lag_2', 'YIELD_RATE_Lag_3'],\n",
      "      dtype='object')\n",
      "\n",
      "Size of data after dropping NaN values: (528, 36)\n",
      "\n",
      "Sample data after creating lags and dropping NaNs:\n",
      "     PRODUCT_ID PRODUCT_TYPE  YIELD_RATE    SHIFT  MACHINE_ID  OPERATOR_ID  \\\n",
      "44           45       Rivian        0.98    Night          15           41   \n",
      "65           66      Bugatti        0.97  Morning           8           29   \n",
      "75           76        Acura        0.86  Morning           5           10   \n",
      "99          100       Jaguar        0.99  Morning           8           34   \n",
      "112         113       Suzuki        1.00  Morning           1           19   \n",
      "\n",
      "    MATERIAL_BATCH  TEMPERATURE  HUMIDITY  DOWNTIME  ...  Horsepower (HP)  \\\n",
      "44        Batch_23        20.01     62.85      1.00  ...              229   \n",
      "65        Batch_74        27.18     57.85      5.11  ...              359   \n",
      "75        Batch_49        29.27     31.37      2.46  ...              346   \n",
      "99        Batch_91        28.52     65.68      2.35  ...              564   \n",
      "112       Batch_27        16.04     45.90      0.25  ...              579   \n",
      "\n",
      "    Torque (Nm) Top Speed (km/h or mph) Acceleration (0-100 km/h or 0-60 mph)  \\\n",
      "44          807                     227                                  3.12   \n",
      "65          725                     320                                  4.82   \n",
      "75          721                     237                                  6.48   \n",
      "99          365                     169                                  8.13   \n",
      "112         779                     278                                  9.29   \n",
      "\n",
      "    Dimensions (L x W x H)  Weight (kg or lbs) Fuel Tank Capacity (liters)  \\\n",
      "44   4764 x 1758 x 1541 mm                1029                        69.0   \n",
      "65   4602 x 1969 x 1507 mm                2116                        65.0   \n",
      "75   4160 x 1821 x 1591 mm                1671                        65.0   \n",
      "99   4356 x 1837 x 1404 mm                1400                        40.0   \n",
      "112  4168 x 1761 x 1556 mm                2087                        51.0   \n",
      "\n",
      "    YIELD_RATE_Lag_1 YIELD_RATE_Lag_2 YIELD_RATE_Lag_3  \n",
      "44              0.89             0.82             0.89  \n",
      "65              0.96             0.97             0.88  \n",
      "75              0.98             0.94             0.81  \n",
      "99              0.91             0.82             0.91  \n",
      "112             0.88             0.96             0.93  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "Sample SHIFT_ENC values:\n",
      "         SHIFT  SHIFT_ENC\n",
      "44       Night          2\n",
      "65     Morning          1\n",
      "118  Afternoon          0\n",
      "PRODUCT_TYPE: Acura | RMSE: 0.0937 | R2: -10.4196\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 112\u001b[0m\n\u001b[1;32m    107\u001b[0m     forecast_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(forecast_results)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast_df\n\u001b[0;32m--> 112\u001b[0m forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_forecast_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# Save or display the forecast results\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecast Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 92\u001b[0m, in \u001b[0;36mtrain_and_forecast_xgboost\u001b[0;34m(data, forecast_years, num_lags)\u001b[0m\n\u001b[1;32m     88\u001b[0m future_forecast \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m future_dates:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Predict the next yield rate\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     predicted_yield \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_known_values\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     93\u001b[0m     future_forecast\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m: product_type,\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRACK_OUT_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPREDICTED_YIELD_RATE\u001b[39m\u001b[38;5;124m'\u001b[39m: predicted_yield\n\u001b[1;32m     97\u001b[0m     })\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Update the lag values for the next iteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:1139\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m test \u001b[38;5;241m=\u001b[39m DMatrix(\n\u001b[1;32m   1132\u001b[0m     X,\n\u001b[1;32m   1133\u001b[0m     base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[1;32m   1138\u001b[0m )\n\u001b[0;32m-> 1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2137\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpecting data to be a DMatrix object, got: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(data))\n\u001b[1;32m   2136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m-> 2137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dmatrix_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2138\u001b[0m iteration_range \u001b[38;5;241m=\u001b[39m _convert_ntree_limit(\u001b[38;5;28mself\u001b[39m, ntree_limit, iteration_range)\n\u001b[1;32m   2139\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: training,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m: strict_shape,\n\u001b[1;32m   2145\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2747\u001b[0m, in \u001b[0;36mBooster._validate_dmatrix_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types \u001b[38;5;241m=\u001b[39m ft\n\u001b[0;32m-> 2747\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:2754\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2754\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2755\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2756\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m   2757\u001b[0m     )\n\u001b[1;32m   2759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names \u001b[38;5;241m!=\u001b[39m feature_names:\n\u001b[1;32m   2760\u001b[0m     dat_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(cast(FeatureNames, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m   2761\u001b[0m         cast(FeatureNames, feature_names)\n\u001b[1;32m   2762\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: training data did not have the following fields: YIELD_RATE_Lag_1, YIELD_RATE_Lag_2, YIELD_RATE_Lag_3, TEMPERATURE, HUMIDITY, DOWNTIME, DEFECT_COUNT, SHIFT_ENC"
     ]
    }
   ],
   "source": [
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        lag_column_name = f'{column}_Lag_{lag}'\n",
    "        data[lag_column_name] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "        print(f\"Created lag column: {lag_column_name}\")\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using XGBoost\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Debug: Check column names after creating lag features\n",
    "    print(\"\\nColumns after creating lag features:\")\n",
    "    print(data.columns)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Debug: Check the size of data after dropping NaNs\n",
    "    print(\"\\nSize of data after dropping NaN values:\", data.shape)\n",
    "\n",
    "    # Debug: Print a sample of the DataFrame\n",
    "    print(\"\\nSample data after creating lags and dropping NaNs:\")\n",
    "    print(data.head())\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Debug: Check if SHIFT_ENC column is created\n",
    "    print(\"\\nSample SHIFT_ENC values:\")\n",
    "    print(data[['SHIFT', 'SHIFT_ENC']].drop_duplicates())\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Debug: Verify that all required columns are present in the DataFrame\n",
    "    missing_features = [col for col in feature_columns if col not in data.columns]\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing features in the DataFrame: {missing_features}\")\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "    # Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508f32d3-51f8-409e-b16f-283ebe106848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in /opt/conda/lib/python3.9/site-packages (1.1.6)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /opt/conda/lib/python3.9/site-packages (from prophet) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.9/site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from prophet) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/conda/lib/python3.9/site-packages (from prophet) (2.2.0)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in /opt/conda/lib/python3.9/site-packages (from prophet) (0.61)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/conda/lib/python3.9/site-packages (from prophet) (4.66.4)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.9/site-packages (from prophet) (6.4.5)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.0.0->prophet) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.0.0->prophet) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.0.0->prophet) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.0.0->prophet) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.0.0->prophet) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.0.0->prophet) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from importlib-resources->prophet) (3.19.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc542b4-5957-43f8-a65a-e92430752be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "05:53:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast Results:\n",
      "     TRACK_OUT_DATE  PREDICTED_YIELD_RATE PRODUCT_TYPE\n",
      "0        2024-10-01              0.927533        Acura\n",
      "1        2024-11-01              0.932099        Acura\n",
      "2        2024-12-01              0.936518        Acura\n",
      "3        2025-01-01              0.941084        Acura\n",
      "4        2025-02-01              0.945650        Acura\n",
      "...             ...                   ...          ...\n",
      "1507     2026-03-01              0.821657        Volvo\n",
      "1508     2026-04-01              0.818800        Volvo\n",
      "1509     2026-05-01              0.816035        Volvo\n",
      "1510     2026-06-01              0.813178        Volvo\n",
      "1511     2026-07-01              0.810413        Volvo\n",
      "\n",
      "[1512 rows x 3 columns]\n",
      "\n",
      "Evaluation Metrics:\n",
      "    PRODUCT_TYPE      RMSE          R2\n",
      "0          Acura  0.093971   -0.222216\n",
      "1     Alfa Romeo  0.069672   -0.941657\n",
      "2   Aston Martin  0.056626   -0.781388\n",
      "3           Audi  0.064916   -3.682253\n",
      "4            BMW  0.070219 -196.226761\n",
      "..           ...       ...         ...\n",
      "58         Tesla  0.015948   -0.011674\n",
      "59        Toyota  0.049661    0.013518\n",
      "60      Vauxhall  0.062209   -3.070604\n",
      "61    Volkswagen  0.062135   -5.177166\n",
      "62         Volvo  0.069744   -6.467508\n",
      "\n",
      "[63 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "#file_path = '/mnt/data/2024-11-15 11_38am (3).csv'\n",
    "#data = pd.read_csv(file_path)\n",
    "data=df\n",
    "# Parse TRACK_OUT_DATE and ensure datetime format\n",
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "# Aggregate data by month (if needed) and group by PRODUCT_TYPE\n",
    "data = data.groupby(['PRODUCT_TYPE', pd.Grouper(key='TRACK_OUT_DATE', freq='MS')])['YIELD_RATE'].mean().reset_index()\n",
    "\n",
    "# Initialize a list to store forecast results and evaluation metrics\n",
    "forecast_results = []\n",
    "evaluation_metrics = []\n",
    "\n",
    "# Loop through each PRODUCT_TYPE (company) to forecast individually\n",
    "for product_type, group_data in data.groupby('PRODUCT_TYPE'):\n",
    "    # Prepare data for Prophet\n",
    "    group_data = group_data.rename(columns={'TRACK_OUT_DATE': 'ds', 'YIELD_RATE': 'y'})\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train_size = int(len(group_data) * 0.8)  # 80% train, 20% test\n",
    "    train_data = group_data.iloc[:train_size]\n",
    "    test_data = group_data.iloc[train_size:]\n",
    "\n",
    "    # Initialize Prophet model\n",
    "    model = Prophet()\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # Predict on test data\n",
    "    future = pd.concat([train_data[['ds']], test_data[['ds']]])\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_forecast = forecast[['ds', 'yhat']].merge(test_data[['ds', 'y']], on='ds', how='inner')\n",
    "    rmse = np.sqrt(mean_squared_error(test_forecast['y'], test_forecast['yhat']))\n",
    "    r2 = r2_score(test_forecast['y'], test_forecast['yhat'])\n",
    "    \n",
    "    # Store evaluation metrics\n",
    "    evaluation_metrics.append({\n",
    "        'PRODUCT_TYPE': product_type,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "    # Forecast for the next 2 years (24 months)\n",
    "    future_dates = model.make_future_dataframe(periods=24, freq='MS')\n",
    "    forecast = model.predict(future_dates)\n",
    "\n",
    "    # Filter for the forecasted dates only\n",
    "    forecast = forecast[['ds', 'yhat']].tail(24)\n",
    "    forecast['PRODUCT_TYPE'] = product_type\n",
    "    forecast = forecast.rename(columns={'ds': 'TRACK_OUT_DATE', 'yhat': 'PREDICTED_YIELD_RATE'})\n",
    "    \n",
    "    # Append forecast results\n",
    "    forecast_results.append(forecast)\n",
    "\n",
    "# Combine all forecasts and evaluation metrics into DataFrames\n",
    "final_forecast_df = pd.concat(forecast_results, ignore_index=True)\n",
    "evaluation_metrics_df = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "# Save or display results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(final_forecast_df)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(evaluation_metrics_df)\n",
    "\n",
    "# If you want to save the results to CSV files:\n",
    "# final_forecast_df.to_csv('/mnt/data/forecast_results.csv', index=False)\n",
    "# evaluation_metrics_df.to_csv('/mnt/data/evaluation_metrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e06ff772-5066-4236-9e40-a4a465af2537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Fit ARIMA model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m ARIMA(train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYIELD_RATE\u001b[39m\u001b[38;5;124m'\u001b[39m], order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Adjust order as needed\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[1;32m     33\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m train_size\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/arima/model.py:395\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, method, method_kwargs, gls, gls_kwargs, cov_type, cov_kwds, return_params, low_memory)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     method_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 395\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_kwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_params:\n\u001b[1;32m    399\u001b[0m         res\u001b[38;5;241m.\u001b[39mfit_details \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mmlefit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/statespace/mlemodel.py:651\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03mFits the model by maximum likelihood via Kalman filter.\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03mstatsmodels.tsa.statespace.structural.UnobservedComponentsResults\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 651\u001b[0m     start_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_params\u001b[49m\n\u001b[1;32m    652\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    653\u001b[0m     includes_fixed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:953\u001b[0m, in \u001b[0;36mSARIMAX.start_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    949\u001b[0m     params_exog \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# Non-seasonal ARMA component and trend\u001b[39;00m\n\u001b[1;32m    952\u001b[0m (params_trend, params_ar, params_ma,\n\u001b[0;32m--> 953\u001b[0m  params_variance) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conditional_sum_squares\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_ar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolynomial_ar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolynomial_ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_k_trend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarning_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mARMA and trend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;66;03m# If we have estimated non-stationary start parameters but enforce\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;66;03m# stationarity is on, start with 0 parameters and warn\u001b[39;00m\n\u001b[1;32m    960\u001b[0m invalid_ar \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_ar \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_stationarity \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_invertible(np\u001b[38;5;241m.\u001b[39mr_[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39mparams_ar])\n\u001b[1;32m    964\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/statsmodels/tsa/statespace/sarimax.py:836\u001b[0m, in \u001b[0;36mSARIMAX._conditional_sum_squares\u001b[0;34m(endog, k_ar, polynomial_ar, k_ma, polynomial_ma, k_trend, trend_data, warning_description)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# If we have MA terms, get residuals from an AR(k) model to use\u001b[39;00m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;66;03m# as data for conditional sum of squares estimates of the MA\u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;66;03m# parameters\u001b[39;00m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k_ma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 836\u001b[0m         Y \u001b[38;5;241m=\u001b[39m \u001b[43mendog\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    837\u001b[0m         X \u001b[38;5;241m=\u001b[39m lagmat(endog, k, trim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    838\u001b[0m         params_ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(X)\u001b[38;5;241m.\u001b[39mdot(Y)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "data=df\n",
    "\n",
    "# Parse TRACK_OUT_DATE and ensure datetime format\n",
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "# Aggregate data by month (if needed) and group by PRODUCT_TYPE\n",
    "data = data.groupby(['PRODUCT_TYPE', pd.Grouper(key='TRACK_OUT_DATE', freq='MS')])['YIELD_RATE'].mean().reset_index()\n",
    "\n",
    "# Initialize a list to store forecast results and evaluation metrics\n",
    "forecast_results = []\n",
    "evaluation_metrics = []\n",
    "\n",
    "# Loop through each PRODUCT_TYPE (company) to forecast individually\n",
    "for product_type, group_data in data.groupby('PRODUCT_TYPE'):\n",
    "    # Sort data by date\n",
    "    group_data = group_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "    # Prepare training and testing data\n",
    "    train_size = int(len(group_data) * 0.8)\n",
    "    train_data = group_data.iloc[:train_size]\n",
    "    test_data = group_data.iloc[train_size:]\n",
    "\n",
    "    # Fit ARIMA model\n",
    "    model = ARIMA(train_data['YIELD_RATE'], order=(1, 1, 1))  # Adjust order as needed\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Predict on test data\n",
    "    start_idx = train_size\n",
    "    end_idx = len(group_data) - 1\n",
    "    test_forecast = model_fit.predict(start=start_idx, end=end_idx, dynamic=False)\n",
    "    test_data['PREDICTED_YIELD_RATE'] = test_forecast.values\n",
    "\n",
    "    # Evaluate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(test_data['YIELD_RATE'], test_data['PREDICTED_YIELD_RATE']))\n",
    "    r2 = r2_score(test_data['YIELD_RATE'], test_data['PREDICTED_YIELD_RATE'])\n",
    "\n",
    "    evaluation_metrics.append({\n",
    "        'PRODUCT_TYPE': product_type,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "    # Forecast for the next 2 years (24 months)\n",
    "    future_forecast = model_fit.forecast(steps=24)\n",
    "    future_dates = pd.date_range(start=group_data['TRACK_OUT_DATE'].max() + pd.offsets.MonthBegin(1), periods=24, freq='MS')\n",
    "\n",
    "    forecast = pd.DataFrame({\n",
    "        'PRODUCT_TYPE': product_type,\n",
    "        'TRACK_OUT_DATE': future_dates,\n",
    "        'PREDICTED_YIELD_RATE': future_forecast\n",
    "    })\n",
    "\n",
    "    forecast_results.append(forecast)\n",
    "\n",
    "# Combine all forecasts and evaluation metrics into DataFrames\n",
    "final_forecast_df = pd.concat(forecast_results, ignore_index=True)\n",
    "evaluation_metrics_df = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "# Save or display results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(final_forecast_df)\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(evaluation_metrics_df)\n",
    "\n",
    "# If you want to save the results to CSV files:\n",
    "# final_forecast_df.to_csv('/mnt/data/forecast_results_arima.csv', index=False)\n",
    "# evaluation_metrics_df.to_csv('/mnt/data/evaluation_metrics_arima.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a385828-6693-4b2a-8af1-d873f1ced173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast Results:\n",
      "   PRODUCT_TYPE TRACK_OUT_DATE  PREDICTED_YIELD_RATE\n",
      "0             0     2024-11-01              0.918213\n",
      "1             0     2024-12-01              0.918213\n",
      "2             0     2025-01-01              0.918213\n",
      "3             0     2025-02-01              0.918213\n",
      "4             0     2025-03-01              0.918213\n",
      "\n",
      "Evaluation Metrics:\n",
      "    PRODUCT_TYPE      RMSE          R2\n",
      "0              0  0.093695  -10.419605\n",
      "1              4  0.066103   -0.328578\n",
      "2              5  0.103775   -1.329908\n",
      "3              6  0.071807    0.000000\n",
      "4              9  0.025855   -1.970977\n",
      "5             10  0.112893   -2.540206\n",
      "6             11  0.118338   -3.173325\n",
      "7             12  0.081661  -22.083434\n",
      "8             13  0.108977   -1.423674\n",
      "9             14  0.062906    0.063384\n",
      "10            16  0.021551    0.000000\n",
      "11            18  0.060342   -0.364365\n",
      "12            19  0.076412   -1.887345\n",
      "13            21  0.108056   -4.101247\n",
      "14            22  0.054840   -0.611137\n",
      "15            24  0.047108   -0.254675\n",
      "16            26  0.044619   -0.244260\n",
      "17            27  0.078689    0.032508\n",
      "18            28  0.044179   -0.593267\n",
      "19            29  0.053080    0.494056\n",
      "20            30  0.130166   -4.186681\n",
      "21            31  0.043406  -17.840417\n",
      "22            32  0.075623   -0.495119\n",
      "23            33  0.009900         NaN\n",
      "24            34  0.078352   -7.911587\n",
      "25            35  0.061303    0.150193\n",
      "26            37  0.076737   -0.035102\n",
      "27            38  0.063690    0.000000\n",
      "28            39  0.065145   -0.224204\n",
      "29            40  0.122013         NaN\n",
      "30            42  0.076112   -0.875446\n",
      "31            43  0.063224   -5.424150\n",
      "32            44  0.047915   -2.332692\n",
      "33            45  0.046079   -1.359178\n",
      "34            46  0.045590    0.158115\n",
      "35            48  0.093288   -0.624970\n",
      "36            49  0.065386    0.118486\n",
      "37            52  0.104583 -163.064048\n",
      "38            53  0.136408  -26.010229\n",
      "39            54  0.112679   -1.871103\n",
      "40            56  0.044112   -1.162097\n",
      "41            57  0.032376    0.344873\n",
      "42            59  0.065195   -0.723116\n",
      "43            61  0.043344  -74.147726\n",
      "44            62  0.060853    0.100912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "data = df\n",
    "\n",
    "# Convert TRACK_OUT_DATE to datetime\n",
    "data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "# Feature Engineering\n",
    "data['MONTH'] = data['TRACK_OUT_DATE'].dt.month\n",
    "data['YEAR'] = data['TRACK_OUT_DATE'].dt.year\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['SHIFT', 'PRODUCT_TYPE']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Create lag features for YIELD_RATE\n",
    "def create_lag_features(data, target_column, group_column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{target_column}_Lag_{lag}'] = data.groupby(group_column)[target_column].shift(lag)\n",
    "    return data\n",
    "\n",
    "data = create_lag_features(data, 'YIELD_RATE', 'PRODUCT_TYPE', num_lags=3)\n",
    "\n",
    "# Drop rows with NaN values created by lags\n",
    "data = data.dropna()\n",
    "\n",
    "# Prepare training features and target\n",
    "features = [\n",
    "    'YIELD_RATE_Lag_1', 'YIELD_RATE_Lag_2', 'YIELD_RATE_Lag_3', \n",
    "    'TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', \n",
    "    'MONTH', 'YEAR', 'SHIFT'\n",
    "]\n",
    "target = 'YIELD_RATE'\n",
    "\n",
    "# Initialize storage for results\n",
    "forecast_results = []\n",
    "evaluation_metrics = []\n",
    "\n",
    "# Forecasting for each PRODUCT_TYPE\n",
    "for product_type, group_data in data.groupby('PRODUCT_TYPE'):\n",
    "    # Sort data by TRACK_OUT_DATE\n",
    "    group_data = group_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "    # Split data into train and test\n",
    "    X = group_data[features]\n",
    "    y = group_data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Train XGBoost Regressor\n",
    "    model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    evaluation_metrics.append({\n",
    "        'PRODUCT_TYPE': product_type,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    })\n",
    "\n",
    "    # Forecast for the next 24 months\n",
    "    future_dates = pd.date_range(start=group_data['TRACK_OUT_DATE'].max() + pd.offsets.MonthBegin(1), periods=24, freq='MS')\n",
    "    last_row = group_data.iloc[-1]\n",
    "\n",
    "    future_data = pd.DataFrame({\n",
    "    'MONTH': future_dates.month,\n",
    "    'YEAR': future_dates.year,\n",
    "    'SHIFT': [last_row['SHIFT']] * len(future_dates),\n",
    "    'TEMPERATURE': [last_row['TEMPERATURE']] * len(future_dates),\n",
    "    'HUMIDITY': [last_row['HUMIDITY']] * len(future_dates),\n",
    "    'DOWNTIME': [last_row['DOWNTIME']] * len(future_dates),\n",
    "    'DEFECT_COUNT': [last_row['DEFECT_COUNT']] * len(future_dates),\n",
    "    'YIELD_RATE_Lag_1': [last_row['YIELD_RATE']] * len(future_dates),\n",
    "    'YIELD_RATE_Lag_2': [last_row['YIELD_RATE_Lag_1']] * len(future_dates),\n",
    "    'YIELD_RATE_Lag_3': [last_row['YIELD_RATE_Lag_2']] * len(future_dates),\n",
    "    })\n",
    "\n",
    "    # Predict future values\n",
    "    future_data['PREDICTED_YIELD_RATE'] = model.predict(future_data[features])\n",
    "    future_data['TRACK_OUT_DATE'] = future_dates\n",
    "    future_data['PRODUCT_TYPE'] = product_type\n",
    "\n",
    "    # Append to forecast results\n",
    "    forecast_results.append(future_data[['PRODUCT_TYPE', 'TRACK_OUT_DATE', 'PREDICTED_YIELD_RATE']])\n",
    "\n",
    "# Combine forecast results and evaluation metrics\n",
    "forecast_df = pd.concat(forecast_results, ignore_index=True)\n",
    "evaluation_metrics_df = pd.DataFrame(evaluation_metrics)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df.head())\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(evaluation_metrics_df)\n",
    "\n",
    "# Save results to CSV\n",
    "# forecast_df.to_csv('/mnt/data/forecast_results_xgboost.csv', index=False)\n",
    "# evaluation_metrics_df.to_csv('/mnt/data/evaluation_metrics_xgboost.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "112dfd5b-41fc-493b-91e6-60916e4c6d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fosforml.model_manager.snowflakesession import get_session\n",
    "my_session = get_session()\n",
    " \n",
    "table_name = '\"FACT_TABLE\"'\n",
    " \n",
    "sf_df = my_session.sql(\"select * from {}\".format(table_name))\n",
    "df = sf_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3325e0e-f639-443d-ac3e-ca4908755a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: 0 | RMSE: 0.0937 | R2: -10.4196\n",
      "PRODUCT_TYPE: 4 | RMSE: 0.0661 | R2: -0.3286\n",
      "PRODUCT_TYPE: 5 | RMSE: 0.1038 | R2: -1.3299\n",
      "PRODUCT_TYPE: 6 | RMSE: 0.0718 | R2: 0.0000\n",
      "PRODUCT_TYPE: 9 | RMSE: 0.0259 | R2: -1.9710\n",
      "PRODUCT_TYPE: 10 | RMSE: 0.1129 | R2: -2.5402\n",
      "PRODUCT_TYPE: 11 | RMSE: 0.1183 | R2: -3.1733\n",
      "PRODUCT_TYPE: 12 | RMSE: 0.0817 | R2: -22.0834\n",
      "PRODUCT_TYPE: 13 | RMSE: 0.1090 | R2: -1.4237\n",
      "PRODUCT_TYPE: 14 | RMSE: 0.0629 | R2: 0.0634\n",
      "PRODUCT_TYPE: 16 | RMSE: 0.0216 | R2: 0.0000\n",
      "PRODUCT_TYPE: 18 | RMSE: 0.0603 | R2: -0.3644\n",
      "PRODUCT_TYPE: 19 | RMSE: 0.0806 | R2: -2.2161\n",
      "PRODUCT_TYPE: 21 | RMSE: 0.1081 | R2: -4.1012\n",
      "PRODUCT_TYPE: 22 | RMSE: 0.0523 | R2: -0.4676\n",
      "PRODUCT_TYPE: 24 | RMSE: 0.0463 | R2: -0.2123\n",
      "PRODUCT_TYPE: 26 | RMSE: 0.0446 | R2: -0.2443\n",
      "PRODUCT_TYPE: 27 | RMSE: 0.0787 | R2: 0.0325\n",
      "PRODUCT_TYPE: 28 | RMSE: 0.0442 | R2: -0.5933\n",
      "PRODUCT_TYPE: 29 | RMSE: 0.0531 | R2: 0.4941\n",
      "PRODUCT_TYPE: 30 | RMSE: 0.1302 | R2: -4.1867\n",
      "PRODUCT_TYPE: 31 | RMSE: 0.0434 | R2: -17.8404\n",
      "PRODUCT_TYPE: 32 | RMSE: 0.0756 | R2: -0.4951\n",
      "PRODUCT_TYPE: 33 | RMSE: 0.0099 | R2: nan\n",
      "PRODUCT_TYPE: 34 | RMSE: 0.0784 | R2: -7.9116\n",
      "PRODUCT_TYPE: 35 | RMSE: 0.0613 | R2: 0.1502\n",
      "PRODUCT_TYPE: 37 | RMSE: 0.0767 | R2: -0.0351\n",
      "PRODUCT_TYPE: 38 | RMSE: 0.0637 | R2: 0.0000\n",
      "PRODUCT_TYPE: 39 | RMSE: 0.0644 | R2: -0.1979\n",
      "PRODUCT_TYPE: 40 | RMSE: 0.1220 | R2: nan\n",
      "PRODUCT_TYPE: 42 | RMSE: 0.0761 | R2: -0.8754\n",
      "PRODUCT_TYPE: 43 | RMSE: 0.0632 | R2: -5.4241\n",
      "PRODUCT_TYPE: 44 | RMSE: 0.0479 | R2: -2.3327\n",
      "PRODUCT_TYPE: 45 | RMSE: 0.0461 | R2: -1.3592\n",
      "PRODUCT_TYPE: 46 | RMSE: 0.0456 | R2: 0.1581\n",
      "PRODUCT_TYPE: 48 | RMSE: 0.0933 | R2: -0.6250\n",
      "PRODUCT_TYPE: 49 | RMSE: 0.0654 | R2: 0.1185\n",
      "PRODUCT_TYPE: 52 | RMSE: 0.1046 | R2: -163.0640\n",
      "PRODUCT_TYPE: 53 | RMSE: 0.1364 | R2: -26.0102\n",
      "PRODUCT_TYPE: 54 | RMSE: 0.1127 | R2: -1.8711\n",
      "PRODUCT_TYPE: 56 | RMSE: 0.0441 | R2: -1.1621\n",
      "PRODUCT_TYPE: 57 | RMSE: 0.0324 | R2: 0.3449\n",
      "PRODUCT_TYPE: 59 | RMSE: 0.0652 | R2: -0.7231\n",
      "PRODUCT_TYPE: 61 | RMSE: 0.0433 | R2: -74.1477\n",
      "PRODUCT_TYPE: 62 | RMSE: 0.0609 | R2: 0.1009\n",
      "\n",
      "Forecast Results:\n",
      "      PRODUCT_TYPE TRACK_OUT_DATE  PREDICTED_YIELD_RATE\n",
      "0                0     2024-11-01              0.918213\n",
      "1                0     2024-12-01              0.918213\n",
      "2                0     2025-01-01              0.918213\n",
      "3                0     2025-02-01              0.918213\n",
      "4                0     2025-03-01              0.918213\n",
      "...            ...            ...                   ...\n",
      "1075            62     2026-07-01              0.918162\n",
      "1076            62     2026-08-01              0.918162\n",
      "1077            62     2026-09-01              0.918162\n",
      "1078            62     2026-10-01              0.918406\n",
      "1079            62     2026-11-01              0.918406\n",
      "\n",
      "[1080 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lag_features(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to prepare training and forecast data\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "    data['MONTH'] = data['TRACK_OUT_DATE'].dt.month\n",
    "    data['YEAR'] = data['TRACK_OUT_DATE'].dt.year\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lag_features(data, 'YIELD_RATE', num_lags)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Define feature columns\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC', 'MONTH', 'YEAR']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize results storage\n",
    "    forecast_results = []\n",
    "\n",
    "    # Train a model for each PRODUCT_TYPE\n",
    "    for product_type, group_data in data.groupby('PRODUCT_TYPE'):\n",
    "        group_data = group_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = group_data[feature_columns]\n",
    "        y = group_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train XGBoost model\n",
    "        model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model performance\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 24 months\n",
    "        future_dates = pd.date_range(start=group_data['TRACK_OUT_DATE'].max() + pd.offsets.MonthBegin(1), periods=24, freq='MS')\n",
    "        last_row = group_data.iloc[-1]\n",
    "\n",
    "        future_data = pd.DataFrame({\n",
    "            'MONTH': future_dates.month,\n",
    "            'YEAR': future_dates.year,\n",
    "            'SHIFT': [last_row['SHIFT']] * len(future_dates),\n",
    "            'TEMPERATURE': [last_row['TEMPERATURE']] * len(future_dates),\n",
    "            'HUMIDITY': [last_row['HUMIDITY']] * len(future_dates),\n",
    "            'DOWNTIME': [last_row['DOWNTIME']] * len(future_dates),\n",
    "            'DEFECT_COUNT': [last_row['DEFECT_COUNT']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_1': [last_row['YIELD_RATE']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_2': [last_row['YIELD_RATE_Lag_1']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_3': [last_row['YIELD_RATE_Lag_2']] * len(future_dates),\n",
    "        })\n",
    "        future_data['SHIFT_ENC'] = le_shift.transform(future_data['SHIFT'])\n",
    "\n",
    "        # Predict future values\n",
    "        future_data['PREDICTED_YIELD_RATE'] = model.predict(future_data[feature_columns])\n",
    "        future_data['TRACK_OUT_DATE'] = future_dates\n",
    "        future_data['PRODUCT_TYPE'] = product_type\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.append(future_data[['PRODUCT_TYPE', 'TRACK_OUT_DATE', 'PREDICTED_YIELD_RATE']])\n",
    "\n",
    "    # Combine forecasts into a single DataFrame\n",
    "    forecast_df = pd.concat(forecast_results, ignore_index=True)\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "\n",
    "# Forecast\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "# Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2566d202-340e-46a2-86cb-6d286a91f642",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:MAINTENANCE_SCHEDULE: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 96\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast_df\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Forecast\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_forecast_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Save or display the forecast results\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecast Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 55\u001b[0m, in \u001b[0;36mtrain_and_forecast_xgboost\u001b[0;34m(data, forecast_years, num_lags)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Train XGBoost model\u001b[39;00m\n\u001b[1;32m     54\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Evaluate model performance\u001b[39;00m\n\u001b[1;32m     58\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:988\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m    987\u001b[0m     evals_result: TrainingCallback\u001b[38;5;241m.\u001b[39mEvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 988\u001b[0m     train_dmatrix, evals \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_evaluation_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin_eval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_qid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_dmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    429\u001b[0m     missing: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    430\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    445\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m    446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     train_dmatrix \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dmatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     n_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(eval_set)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnthread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/data.py:970\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_pandas_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_series(data):\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_pandas_series(\n\u001b[1;32m    974\u001b[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001b[1;32m    975\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/data.py:417\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_pandas_df\u001b[39m(\n\u001b[1;32m    410\u001b[0m     data: DataFrame,\n\u001b[1;32m    411\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    416\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[0;32m--> 417\u001b[0m     data, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43m_transform_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/data.py:391\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    380\u001b[0m     is_sparse,\n\u001b[1;32m    381\u001b[0m     is_categorical_dtype,\n\u001b[1;32m    382\u001b[0m )\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    385\u001b[0m     dtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _pandas_dtype_mapper\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_sparse(dtype)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtypes\n\u001b[1;32m    390\u001b[0m ):\n\u001b[0;32m--> 391\u001b[0m     \u001b[43m_invalid_dataframe_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m feature_names, feature_types \u001b[38;5;241m=\u001b[39m _pandas_feature_info(\n\u001b[1;32m    394\u001b[0m     data, meta, feature_names, feature_types, enable_categorical\n\u001b[1;32m    395\u001b[0m )\n\u001b[1;32m    397\u001b[0m transformed \u001b[38;5;241m=\u001b[39m _pandas_cat_null(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/xgboost/data.py:283\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    281\u001b[0m type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:MAINTENANCE_SCHEDULE: object"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lag_features(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to prepare training and forecast data\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "    data['MONTH'] = data['TRACK_OUT_DATE'].dt.month\n",
    "    data['YEAR'] = data['TRACK_OUT_DATE'].dt.year\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lag_features(data, 'YIELD_RATE', num_lags)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Define updated feature columns\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]  # Lagged Yield Rates\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT']  # Environmental and operational\n",
    "        + ['MONTH', 'YEAR']  # Date components\n",
    "        + ['MAINTENANCE_SCHEDULE', 'MACHINE_ID', 'OPERATOR_ID']  # Maintenance and operational context\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize results storage\n",
    "    forecast_results = []\n",
    "\n",
    "    # Train a model for each PRODUCT_TYPE\n",
    "    for product_type, group_data in data.groupby('PRODUCT_TYPE'):\n",
    "        group_data = group_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = group_data[feature_columns]\n",
    "        y = group_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train XGBoost model\n",
    "        model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model performance\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 24 months\n",
    "        future_dates = pd.date_range(start=group_data['TRACK_OUT_DATE'].max() + pd.offsets.MonthBegin(1), periods=24, freq='MS')\n",
    "        last_row = group_data.iloc[-1]\n",
    "\n",
    "        future_data = pd.DataFrame({\n",
    "            'MONTH': future_dates.month,\n",
    "            'YEAR': future_dates.year,\n",
    "            'TEMPERATURE': [last_row['TEMPERATURE']] * len(future_dates),\n",
    "            'HUMIDITY': [last_row['HUMIDITY']] * len(future_dates),\n",
    "            'DOWNTIME': [last_row['DOWNTIME']] * len(future_dates),\n",
    "            'DEFECT_COUNT': [last_row['DEFECT_COUNT']] * len(future_dates),\n",
    "            'MAINTENANCE_SCHEDULE': [last_row['MAINTENANCE_SCHEDULE']] * len(future_dates),\n",
    "            'MACHINE_ID': [last_row['MACHINE_ID']] * len(future_dates),\n",
    "            'OPERATOR_ID': [last_row['OPERATOR_ID']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_1': [last_row['YIELD_RATE']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_2': [last_row['YIELD_RATE_Lag_1']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_3': [last_row['YIELD_RATE_Lag_2']] * len(future_dates),\n",
    "        })\n",
    "\n",
    "        # Predict future values\n",
    "        future_data['PREDICTED_YIELD_RATE'] = model.predict(future_data[feature_columns])\n",
    "        future_data['TRACK_OUT_DATE'] = future_dates\n",
    "        future_data['PRODUCT_TYPE'] = product_type\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.append(future_data[['PRODUCT_TYPE', 'TRACK_OUT_DATE', 'PREDICTED_YIELD_RATE']])\n",
    "\n",
    "    # Combine forecasts into a single DataFrame\n",
    "    forecast_df = pd.concat(forecast_results, ignore_index=True)\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "# Forecast\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "# Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2113dfc-7461-422f-a737-7f183853f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: 0 | RMSE: 0.0928 | R2: -10.2006\n",
      "PRODUCT_TYPE: 4 | RMSE: 0.0649 | R2: -0.2801\n",
      "PRODUCT_TYPE: 5 | RMSE: 0.0815 | R2: -0.4377\n",
      "PRODUCT_TYPE: 6 | RMSE: 0.0674 | R2: 0.0000\n",
      "PRODUCT_TYPE: 9 | RMSE: 0.0259 | R2: -1.9710\n",
      "PRODUCT_TYPE: 10 | RMSE: 0.1000 | R2: -1.7776\n",
      "PRODUCT_TYPE: 11 | RMSE: 0.1201 | R2: -3.2967\n",
      "PRODUCT_TYPE: 12 | RMSE: 0.1028 | R2: -35.5997\n",
      "PRODUCT_TYPE: 13 | RMSE: 0.1090 | R2: -1.4237\n",
      "PRODUCT_TYPE: 14 | RMSE: 0.0548 | R2: 0.2889\n",
      "PRODUCT_TYPE: 16 | RMSE: 0.0394 | R2: 0.0000\n",
      "PRODUCT_TYPE: 18 | RMSE: 0.0568 | R2: -0.2091\n",
      "PRODUCT_TYPE: 19 | RMSE: 0.0632 | R2: -0.9740\n",
      "PRODUCT_TYPE: 21 | RMSE: 0.1082 | R2: -4.1167\n",
      "PRODUCT_TYPE: 22 | RMSE: 0.0378 | R2: 0.2326\n",
      "PRODUCT_TYPE: 24 | RMSE: 0.0309 | R2: 0.4599\n",
      "PRODUCT_TYPE: 26 | RMSE: 0.0446 | R2: -0.2423\n",
      "PRODUCT_TYPE: 27 | RMSE: 0.0731 | R2: 0.1651\n",
      "PRODUCT_TYPE: 28 | RMSE: 0.0437 | R2: -0.5597\n",
      "PRODUCT_TYPE: 29 | RMSE: 0.0478 | R2: 0.5891\n",
      "PRODUCT_TYPE: 30 | RMSE: 0.1202 | R2: -3.4224\n",
      "PRODUCT_TYPE: 31 | RMSE: 0.0434 | R2: -17.8199\n",
      "PRODUCT_TYPE: 32 | RMSE: 0.0760 | R2: -0.5108\n",
      "PRODUCT_TYPE: 33 | RMSE: 0.0099 | R2: nan\n",
      "PRODUCT_TYPE: 34 | RMSE: 0.1010 | R2: -13.8054\n",
      "PRODUCT_TYPE: 35 | RMSE: 0.0613 | R2: 0.1489\n",
      "PRODUCT_TYPE: 37 | RMSE: 0.0763 | R2: -0.0242\n",
      "PRODUCT_TYPE: 38 | RMSE: 0.0827 | R2: 0.0000\n",
      "PRODUCT_TYPE: 39 | RMSE: 0.0706 | R2: -0.4382\n",
      "PRODUCT_TYPE: 40 | RMSE: 0.1220 | R2: nan\n",
      "PRODUCT_TYPE: 42 | RMSE: 0.0420 | R2: 0.4289\n",
      "PRODUCT_TYPE: 43 | RMSE: 0.0570 | R2: -4.2179\n",
      "PRODUCT_TYPE: 44 | RMSE: 0.0486 | R2: -2.4314\n",
      "PRODUCT_TYPE: 45 | RMSE: 0.0461 | R2: -1.3592\n",
      "PRODUCT_TYPE: 46 | RMSE: 0.0485 | R2: 0.0476\n",
      "PRODUCT_TYPE: 48 | RMSE: 0.0933 | R2: -0.6249\n",
      "PRODUCT_TYPE: 49 | RMSE: 0.0747 | R2: -0.1496\n",
      "PRODUCT_TYPE: 52 | RMSE: 0.1008 | R2: -151.3626\n",
      "PRODUCT_TYPE: 53 | RMSE: 0.1161 | R2: -18.5631\n",
      "PRODUCT_TYPE: 54 | RMSE: 0.0878 | R2: -0.7433\n",
      "PRODUCT_TYPE: 56 | RMSE: 0.0310 | R2: -0.0646\n",
      "PRODUCT_TYPE: 57 | RMSE: 0.0323 | R2: 0.3480\n",
      "PRODUCT_TYPE: 59 | RMSE: 0.0650 | R2: -0.7147\n",
      "PRODUCT_TYPE: 61 | RMSE: 0.0428 | R2: -72.1803\n",
      "PRODUCT_TYPE: 62 | RMSE: 0.0835 | R2: -0.6938\n",
      "\n",
      "Forecast Results:\n",
      "      PRODUCT_TYPE TRACK_OUT_DATE  PREDICTED_YIELD_RATE\n",
      "0                0     2024-11-01              0.903821\n",
      "1                0     2024-12-01              0.903821\n",
      "2                0     2025-01-01              0.903821\n",
      "3                0     2025-02-01              0.903821\n",
      "4                0     2025-03-01              0.903821\n",
      "...            ...            ...                   ...\n",
      "1075            62     2026-07-01              0.886559\n",
      "1076            62     2026-08-01              0.886559\n",
      "1077            62     2026-09-01              0.886559\n",
      "1078            62     2026-10-01              0.886559\n",
      "1079            62     2026-11-01              0.886559\n",
      "\n",
      "[1080 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lag_features(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to prepare training and forecast data\n",
    "def train_and_forecast_xgboost(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "    data['MONTH'] = data['TRACK_OUT_DATE'].dt.month\n",
    "    data['YEAR'] = data['TRACK_OUT_DATE'].dt.year\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lag_features(data, 'YIELD_RATE', num_lags)\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    le_maintenance = LabelEncoder()\n",
    "    data['MAINTENANCE_SCHEDULE_ENC'] = le_maintenance.fit_transform(data['MAINTENANCE_SCHEDULE'])\n",
    "\n",
    "    le_machine = LabelEncoder()\n",
    "    data['MACHINE_ID_ENC'] = le_machine.fit_transform(data['MACHINE_ID'])\n",
    "\n",
    "    le_operator = LabelEncoder()\n",
    "    data['OPERATOR_ID_ENC'] = le_operator.fit_transform(data['OPERATOR_ID'])\n",
    "\n",
    "    # Define updated feature columns\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]  # Lagged Yield Rates\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT']  # Environmental and operational\n",
    "        + ['MONTH', 'YEAR']  # Date components\n",
    "        + ['MAINTENANCE_SCHEDULE_ENC', 'MACHINE_ID_ENC', 'OPERATOR_ID_ENC']  # Encoded categorical features\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize results storage\n",
    "    forecast_results = []\n",
    "\n",
    "    # Train a model for each PRODUCT_TYPE\n",
    "    for product_type, group_data in data.groupby('PRODUCT_TYPE'):\n",
    "        group_data = group_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = group_data[feature_columns]\n",
    "        y = group_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train XGBoost model\n",
    "        model = XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model performance\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 24 months\n",
    "        future_dates = pd.date_range(start=group_data['TRACK_OUT_DATE'].max() + pd.offsets.MonthBegin(1), periods=24, freq='MS')\n",
    "        last_row = group_data.iloc[-1]\n",
    "\n",
    "        future_data = pd.DataFrame({\n",
    "            'MONTH': future_dates.month,\n",
    "            'YEAR': future_dates.year,\n",
    "            'TEMPERATURE': [last_row['TEMPERATURE']] * len(future_dates),\n",
    "            'HUMIDITY': [last_row['HUMIDITY']] * len(future_dates),\n",
    "            'DOWNTIME': [last_row['DOWNTIME']] * len(future_dates),\n",
    "            'DEFECT_COUNT': [last_row['DEFECT_COUNT']] * len(future_dates),\n",
    "            'MAINTENANCE_SCHEDULE_ENC': [last_row['MAINTENANCE_SCHEDULE_ENC']] * len(future_dates),\n",
    "            'MACHINE_ID_ENC': [last_row['MACHINE_ID_ENC']] * len(future_dates),\n",
    "            'OPERATOR_ID_ENC': [last_row['OPERATOR_ID_ENC']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_1': [last_row['YIELD_RATE']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_2': [last_row['YIELD_RATE_Lag_1']] * len(future_dates),\n",
    "            'YIELD_RATE_Lag_3': [last_row['YIELD_RATE_Lag_2']] * len(future_dates),\n",
    "        })\n",
    "\n",
    "        # Predict future values\n",
    "        future_data['PREDICTED_YIELD_RATE'] = model.predict(future_data[feature_columns])\n",
    "        future_data['TRACK_OUT_DATE'] = future_dates\n",
    "        future_data['PRODUCT_TYPE'] = product_type\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.append(future_data[['PRODUCT_TYPE', 'TRACK_OUT_DATE', 'PREDICTED_YIELD_RATE']])\n",
    "\n",
    "    # Combine forecasts into a single DataFrame\n",
    "    forecast_df = pd.concat(forecast_results, ignore_index=True)\n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "# Forecast\n",
    "forecast_df = train_and_forecast_xgboost(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "# Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300cced9-64c1-42f8-8a1c-3c51935bcd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: 0 | RMSE: 0.1240 | R2: -19.0118\n",
      "PRODUCT_TYPE: 4 | RMSE: 0.0477 | R2: 0.3090\n",
      "PRODUCT_TYPE: 5 | RMSE: 0.4182 | R2: -36.8365\n",
      "PRODUCT_TYPE: 6 | RMSE: 0.1003 | R2: 0.0000\n",
      "PRODUCT_TYPE: 9 | RMSE: 0.4972 | R2: -1097.7248\n",
      "PRODUCT_TYPE: 10 | RMSE: 0.1209 | R2: -3.0571\n",
      "PRODUCT_TYPE: 11 | RMSE: 0.0496 | R2: 0.2659\n",
      "PRODUCT_TYPE: 12 | RMSE: 1.0069 | R2: -3508.5969\n",
      "PRODUCT_TYPE: 13 | RMSE: 0.1207 | R2: -1.9750\n",
      "PRODUCT_TYPE: 14 | RMSE: 0.0850 | R2: -0.7117\n",
      "PRODUCT_TYPE: 16 | RMSE: 0.0905 | R2: 0.0000\n",
      "PRODUCT_TYPE: 18 | RMSE: 0.0920 | R2: -2.1711\n",
      "PRODUCT_TYPE: 19 | RMSE: 0.1547 | R2: -10.8288\n",
      "PRODUCT_TYPE: 21 | RMSE: 3.3248 | R2: -4828.4290\n",
      "PRODUCT_TYPE: 22 | RMSE: 0.0315 | R2: 0.4694\n",
      "PRODUCT_TYPE: 24 | RMSE: 0.1506 | R2: -11.8290\n",
      "PRODUCT_TYPE: 26 | RMSE: 0.0600 | R2: -1.2498\n",
      "PRODUCT_TYPE: 27 | RMSE: 0.2179 | R2: -6.4194\n",
      "PRODUCT_TYPE: 28 | RMSE: 0.1812 | R2: -25.8137\n",
      "PRODUCT_TYPE: 29 | RMSE: 0.1410 | R2: -2.5716\n",
      "PRODUCT_TYPE: 30 | RMSE: 0.1427 | R2: -5.2358\n",
      "PRODUCT_TYPE: 31 | RMSE: 0.1672 | R2: -278.4025\n",
      "PRODUCT_TYPE: 32 | RMSE: 0.0759 | R2: -0.5064\n",
      "PRODUCT_TYPE: 33 | RMSE: 0.0464 | R2: nan\n",
      "PRODUCT_TYPE: 34 | RMSE: 0.0872 | R2: -10.0463\n",
      "PRODUCT_TYPE: 35 | RMSE: 0.0969 | R2: -1.1240\n",
      "PRODUCT_TYPE: 37 | RMSE: 0.1322 | R2: -2.0729\n",
      "PRODUCT_TYPE: 38 | RMSE: 0.1868 | R2: 0.0000\n",
      "PRODUCT_TYPE: 39 | RMSE: 0.1387 | R2: -4.5467\n",
      "PRODUCT_TYPE: 40 | RMSE: 0.1200 | R2: nan\n",
      "PRODUCT_TYPE: 42 | RMSE: 0.1216 | R2: -3.7866\n",
      "PRODUCT_TYPE: 43 | RMSE: 0.1114 | R2: -18.9561\n",
      "PRODUCT_TYPE: 44 | RMSE: 0.1454 | R2: -29.6912\n",
      "PRODUCT_TYPE: 45 | RMSE: 0.1938 | R2: -40.7527\n",
      "PRODUCT_TYPE: 46 | RMSE: 0.1251 | R2: -5.3403\n",
      "PRODUCT_TYPE: 48 | RMSE: 0.1328 | R2: -2.2944\n",
      "PRODUCT_TYPE: 49 | RMSE: 0.0836 | R2: -0.4424\n",
      "PRODUCT_TYPE: 52 | RMSE: 0.1997 | R2: -596.9036\n",
      "PRODUCT_TYPE: 53 | RMSE: 0.2915 | R2: -122.3081\n",
      "PRODUCT_TYPE: 54 | RMSE: 0.3674 | R2: -29.5169\n",
      "PRODUCT_TYPE: 56 | RMSE: 0.2383 | R2: -62.1129\n",
      "PRODUCT_TYPE: 57 | RMSE: 0.1141 | R2: -7.1425\n",
      "PRODUCT_TYPE: 59 | RMSE: 0.1288 | R2: -5.7246\n",
      "PRODUCT_TYPE: 61 | RMSE: 0.2962 | R2: -3508.7163\n",
      "PRODUCT_TYPE: 62 | RMSE: 0.0650 | R2: -0.0271\n",
      "\n",
      "Forecast Results:\n",
      "      PRODUCT_TYPE TRACK_OUT_DATE  PREDICTED_YIELD_RATE\n",
      "0                0     2024-11-16              0.832556\n",
      "1                0     2024-12-16              1.508122\n",
      "2                0     2025-01-15              1.849073\n",
      "3                0     2025-02-14             -0.192072\n",
      "4                0     2025-03-16              0.111748\n",
      "...            ...            ...                   ...\n",
      "1075            62     2026-07-10              1.381476\n",
      "1076            62     2026-08-09              1.846795\n",
      "1077            62     2026-09-08              2.074770\n",
      "1078            62     2026-10-08              1.992810\n",
      "1079            62     2026-11-07              1.680789\n",
      "\n",
      "[1080 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using Linear Regression\n",
    "def train_and_forecast_linear_regression(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the Linear Regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R2: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "# Assuming df is your DataFrame loaded from the CSV file.\n",
    "# df = pd.read_csv('your_dataset.csv')  # Uncomment this line to load your dataset\n",
    "\n",
    "# For demonstration purposes, let's create a sample DataFrame similar to your description.\n",
    "\n",
    "#df_sample = pd.DataFrame(data_sample)\n",
    "\n",
    "forecast_df = train_and_forecast_linear_regression(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "# Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0cdcaf6-a95d-4af6-abaf-da612f640805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCT_TYPE: 0 | Cross-Validation R²: -141.9068\n",
      "PRODUCT_TYPE: 0 | RMSE: 0.1240 | R²: -19.0118\n",
      "PRODUCT_TYPE: 4 | Cross-Validation R²: -71.2620\n",
      "PRODUCT_TYPE: 4 | RMSE: 0.0477 | R²: 0.3090\n",
      "PRODUCT_TYPE: 5 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 5 | RMSE: 0.4182 | R²: -36.8365\n",
      "PRODUCT_TYPE: 6 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 6 | RMSE: 0.1002 | R²: 0.0000\n",
      "PRODUCT_TYPE: 9 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 9 | RMSE: 0.0177 | R²: -0.3851\n",
      "PRODUCT_TYPE: 10 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 10 | RMSE: 0.0775 | R²: -0.6693\n",
      "PRODUCT_TYPE: 11 | Cross-Validation R²: -2509.1126\n",
      "PRODUCT_TYPE: 11 | RMSE: 0.0496 | R²: 0.2659\n",
      "PRODUCT_TYPE: 12 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 12 | RMSE: 1.0069 | R²: -3508.5969\n",
      "PRODUCT_TYPE: 13 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 13 | RMSE: 0.1060 | R²: -1.2940\n",
      "PRODUCT_TYPE: 14 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 14 | RMSE: 0.0572 | R²: 0.2248\n",
      "PRODUCT_TYPE: 16 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 16 | RMSE: 0.0784 | R²: 0.0000\n",
      "PRODUCT_TYPE: 18 | Cross-Validation R²: -869.0310\n",
      "PRODUCT_TYPE: 18 | RMSE: 0.0920 | R²: -2.1711\n",
      "PRODUCT_TYPE: 19 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 19 | RMSE: 0.1289 | R²: -7.2147\n",
      "PRODUCT_TYPE: 21 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 21 | RMSE: 0.4284 | R²: -79.1706\n",
      "PRODUCT_TYPE: 22 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 22 | RMSE: 0.0315 | R²: 0.4694\n",
      "PRODUCT_TYPE: 24 | Cross-Validation R²: -15.1161\n",
      "PRODUCT_TYPE: 24 | RMSE: 0.1506 | R²: -11.8290\n",
      "PRODUCT_TYPE: 26 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 26 | RMSE: 0.0482 | R²: -0.4543\n",
      "PRODUCT_TYPE: 27 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 27 | RMSE: 0.1620 | R²: -3.0990\n",
      "PRODUCT_TYPE: 28 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 28 | RMSE: 0.1727 | R²: -23.3419\n",
      "PRODUCT_TYPE: 29 | Cross-Validation R²: -114.8768\n",
      "PRODUCT_TYPE: 29 | RMSE: 0.1410 | R²: -2.5716\n",
      "PRODUCT_TYPE: 30 | Cross-Validation R²: -960.0883\n",
      "PRODUCT_TYPE: 30 | RMSE: 0.1427 | R²: -5.2358\n",
      "PRODUCT_TYPE: 31 | Cross-Validation R²: nan\n",
      "PRODUCT_TYPE: 31 | RMSE: 0.0800 | R²: -62.9538\n",
      "PRODUCT_TYPE: 32 | Cross-Validation R²: -341.4120\n",
      "PRODUCT_TYPE: 32 | RMSE: 0.0759 | R²: -0.5064\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 104\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forecast_df\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Assuming df is your DataFrame loaded from the CSV file.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv('your_dataset.csv')  # Uncomment this line to load your dataset\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# For demonstration purposes, let's create a sample DataFrame similar to your description.\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m forecast_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_forecast_linear_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_years\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Save or display the forecast results\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecast Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 60\u001b[0m, in \u001b[0;36mtrain_and_forecast_linear_regression\u001b[0;34m(data, forecast_years, num_lags)\u001b[0m\n\u001b[1;32m     57\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Evaluate the model using cross-validation\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRODUCT_TYPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Cross-Validation R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1844\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[0;32m-> 1844\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1845\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/parallel.py:70\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m---> 70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m    426\u001b[0m         X,\n\u001b[1;32m    427\u001b[0m         y,\n\u001b[1;32m    428\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    429\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    430\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    431\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    432\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    433\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    434\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    435\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    436\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    437\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    438\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    439\u001b[0m     )\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    441\u001b[0m )\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py:409\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    407\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         (\n\u001b[1;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[1;32m    414\u001b[0m     )\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=2."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lags(data, column, num_lags):\n",
    "    for lag in range(1, num_lags + 1):\n",
    "        data[f'{column}_Lag_{lag}'] = data.groupby('PRODUCT_TYPE')[column].shift(lag)\n",
    "    return data\n",
    "\n",
    "# Function to train and forecast using Linear Regression\n",
    "def train_and_forecast_linear_regression(data, forecast_years=2, num_lags=3):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Create lag features for YIELD_RATE\n",
    "    data = create_lags(data, 'YIELD_RATE', num_lags)\n",
    "\n",
    "    # Drop rows with NaN values due to lag creation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = (\n",
    "        [f'YIELD_RATE_Lag_{i}' for i in range(1, num_lags + 1)]\n",
    "        + ['TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC']\n",
    "    )\n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    data[feature_columns] = scaler.fit_transform(data[feature_columns])\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the Linear Regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model using cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | Cross-Validation R²: {cv_scores.mean():.4f}\")\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R²: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the lag values for the next iteration\n",
    "            last_known_values = np.roll(last_known_values, shift=1)\n",
    "            last_known_values[0] = predicted_yield\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "# Assuming df is your DataFrame loaded from the CSV file.\n",
    "# df = pd.read_csv('your_dataset.csv')  # Uncomment this line to load your dataset\n",
    "\n",
    "# For demonstration purposes, let's create a sample DataFrame similar to your description.\n",
    "\n",
    "\n",
    "forecast_df = train_and_forecast_linear_regression(df, forecast_years=2, num_lags=3)\n",
    "\n",
    "# Save or display the forecast results\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a625ea22-b1a5-417d-83cc-e7d628c92d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '4160 x 1821 x 1591 mm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2087/681049572.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2087/681049572.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data, forecast_years)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtarget_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'YIELD_RATE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Standardize features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Initialize storage for forecasts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mforecast_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 )\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \"\"\"\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[1;32m    913\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 ) from complex_warning\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m         if (\n\u001b[1;32m   2152\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '4160 x 1821 x 1591 mm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to train and forecast using Random Forest Regressor\n",
    "def train_and_forecast_random_forest(data, forecast_years=2):\n",
    "    # Convert TRACK_OUT_DATE to datetime\n",
    "    data['TRACK_OUT_DATE'] = pd.to_datetime(data['TRACK_OUT_DATE'])\n",
    "\n",
    "    # Encode categorical features\n",
    "    le_shift = LabelEncoder()\n",
    "    le_product_type = LabelEncoder()\n",
    "    le_machine_id = LabelEncoder()\n",
    "    le_operator_id = LabelEncoder()\n",
    "    le_material_batch = LabelEncoder()\n",
    "    le_model_name = LabelEncoder()\n",
    "    le_engine_type = LabelEncoder()\n",
    "    le_fuel_type = LabelEncoder()\n",
    "    le_transmission_type = LabelEncoder()\n",
    "    le_body_style = LabelEncoder()\n",
    "    le_color_options = LabelEncoder()\n",
    "    le_safety_features = LabelEncoder()\n",
    "\n",
    "    data['SHIFT_ENC'] = le_shift.fit_transform(data['SHIFT'])\n",
    "    data['PRODUCT_TYPE_ENC'] = le_product_type.fit_transform(data['PRODUCT_TYPE'])\n",
    "    data['MACHINE_ID_ENC'] = le_machine_id.fit_transform(data['MACHINE_ID'])\n",
    "    data['OPERATOR_ID_ENC'] = le_operator_id.fit_transform(data['OPERATOR_ID'])\n",
    "    data['MATERIAL_BATCH_ENC'] = le_material_batch.fit_transform(data['MATERIAL_BATCH'])\n",
    "    data['MODEL_NAME_ENC'] = le_model_name.fit_transform(data['MODEL_NAME'])\n",
    "    data['ENGINE_TYPE_ENC'] = le_engine_type.fit_transform(data['ENGINE_TYPE'])\n",
    "    data['FUEL_TYPE_ENC'] = le_fuel_type.fit_transform(data['FUEL_TYPE'])\n",
    "    data['TRANSMISSION_TYPE_ENC'] = le_transmission_type.fit_transform(data['TRANSMISSION_TYPE'])\n",
    "    data['BODY_STYLE_ENC'] = le_body_style.fit_transform(data['BODY_STYLE'])\n",
    "    data['COLOR_OPTIONS_ENC'] = le_color_options.fit_transform(data['COLOR_OPTIONS'])\n",
    "    data['SAFETY_FEATURES_ENC'] = le_safety_features.fit_transform(data['SAFETY_FEATURES'])\n",
    "\n",
    "    # Select features for training\n",
    "    feature_columns = [\n",
    "        'TEMPERATURE', 'HUMIDITY', 'DOWNTIME', 'DEFECT_COUNT', 'SHIFT_ENC',\n",
    "        'PRODUCT_TYPE_ENC', 'MACHINE_ID_ENC', 'OPERATOR_ID_ENC', 'MATERIAL_BATCH_ENC',\n",
    "        'MODEL_NAME_ENC', 'YEAR_OF_MANUFACTURE', 'ENGINE_TYPE_ENC', 'FUEL_TYPE_ENC',\n",
    "        'TRANSMISSION_TYPE_ENC', 'BODY_STYLE_ENC', 'Price(in Dollars)', \n",
    "        'Mileage (km/l or mpg)', 'SEATING_CAPACITY', 'COLOR_OPTIONS_ENC',\n",
    "        'SAFETY_FEATURES_ENC', 'Warranty Period(in Years)', 'Horsepower (HP)',\n",
    "        'Torque (Nm)', 'Top Speed (km/h or mph)', 'Acceleration (0-100 km/h or 0-60 mph)',\n",
    "        'Dimensions (L x W x H)', 'Weight (kg or lbs)', 'Fuel Tank Capacity (liters)'\n",
    "    ]\n",
    "    \n",
    "    target_column = 'YIELD_RATE'\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    data[feature_columns] = scaler.fit_transform(data[feature_columns])\n",
    "\n",
    "    # Initialize storage for forecasts\n",
    "    forecast_results = []\n",
    "\n",
    "    # Loop through each PRODUCT_TYPE\n",
    "    for product_type, type_data in data.groupby('PRODUCT_TYPE'):\n",
    "        type_data = type_data.sort_values('TRACK_OUT_DATE')\n",
    "\n",
    "        # Prepare training data\n",
    "        X = type_data[feature_columns]\n",
    "        y = type_data[target_column]\n",
    "\n",
    "        # Split into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        # Train the Random Forest Regressor model\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model using cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | Cross-Validation R²: {cv_scores.mean():.4f}\")\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"PRODUCT_TYPE: {product_type} | RMSE: {rmse:.4f} | R²: {r2:.4f}\")\n",
    "\n",
    "        # Forecast for the next 2 years (24 months)\n",
    "        last_date = type_data['TRACK_OUT_DATE'].max()\n",
    "        future_dates = [last_date + timedelta(days=30 * i) for i in range(1, 24 + 1)]\n",
    "\n",
    "        # Start forecasting\n",
    "        last_known_values = type_data.iloc[-1][feature_columns].values\n",
    "        future_forecast = []\n",
    "\n",
    "        for date in future_dates:\n",
    "            # Predict the next yield rate\n",
    "            predicted_yield = model.predict([last_known_values])[0]\n",
    "            future_forecast.append({\n",
    "                'PRODUCT_TYPE': product_type,\n",
    "                'TRACK_OUT_DATE': date,\n",
    "                'PREDICTED_YIELD_RATE': predicted_yield\n",
    "            })\n",
    "\n",
    "            # Update the feature values for the next iteration (excluding lag features)\n",
    "            last_known_values[:len(feature_columns)] = last_known_values[:len(feature_columns)]\n",
    "\n",
    "        # Store results\n",
    "        forecast_results.extend(future_forecast)\n",
    "\n",
    "    # Combine all forecasts into a DataFrame\n",
    "    forecast_df = pd.DataFrame(forecast_results)\n",
    "\n",
    "    return forecast_df\n",
    "\n",
    "# Assuming df is your DataFrame loaded from the CSV file.\n",
    "# df = pd.read_csv('your_dataset.csv')  # Uncomment this line to load your dataset\n",
    "\n",
    "\n",
    "\n",
    "forecast_df = train_and_forecast_random_forest(df, forecast_years=2)\n",
    "\n",
    "print(\"\\nForecast Results:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e199d-6e43-42e0-84fe-469fb56f1341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
